{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV,StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import     RandomOverSampler \n",
    "from imblearn.under_sampling import     RandomUnderSampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scikitplot import clustering_factory\n",
    "from scikitplot import classifier_factory\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_result(clf,X_test):\n",
    "    Y_pred=clf.predict(X_test)\n",
    "    res_file=open('result.csv', 'w')\n",
    "    for y_item in Y_pred:\n",
    "      res_file.write(\"%s\\n\" % y_item)\n",
    "    res_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train=pd.read_csv('x_train.csv',delimiter=\";\",header=None,names=['f'+str(i) for i in range (223)])\n",
    "all_target=pd.read_csv('y_train.csv',names=['class'])\n",
    "all_target=all_target['class']\n",
    "all_test=pd.read_csv('x_test.csv',delimiter=\";\",header=None,names=['f'+str(i) for i in range (223)])\n",
    "base_col=all_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделяем hold-out выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_train, all_target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Функция для оценки качества модели\n",
    "def show_score(clf,X_train, X_test, y_train, y_test,cv=5):\n",
    "    # Оценка на отложенной выборке\n",
    "    clf.fit(X_train,y_train)\n",
    "    holdout_score=clf.score(X_test,y_test)\n",
    "    print (\"Holdout :\",holdout_score)\n",
    "    # Оценка кросс валидации на тестовой выборке\n",
    "    cv_score=np.mean(cross_val_score(clf, X_train, y_train, cv=cv))\n",
    "    #cv_score=np.mean(cross_val_score(clf, all_train[col], all_target, cv=cv))\n",
    "    print (\"Crossval:\",cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Готовые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самая простая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout : 0.493923611111\n",
      "Crossval: 0.470301233772\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "show_score(rf,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель с затюниными параметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout : 0.566840277778\n",
      "Crossval: 0.537479889966\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(max_features='auto',n_estimators=300,max_depth=100,random_state=42)\n",
    "show_score(rf,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель с лучшими колонками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout : 0.631944444444\n",
      "Crossval: 0.576796110362\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(max_features='auto',n_estimators=300,max_depth=100,random_state=42)\n",
    "best_cols=['f138', 'f96', 'f76', 'f11', 'f185', 'f115','f131', 'f83']\n",
    "show_score(rf,X_train[best_cols], X_test[best_cols], y_train, y_test,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Устредненная по seed модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout : 0.641493055556\n",
      "Crossval: 0.581916619668\n"
     ]
    }
   ],
   "source": [
    "rf1=RandomForestClassifier(max_features='auto',n_estimators=300,max_depth=100,random_state=1,class_weight='balanced')\n",
    "rf2=RandomForestClassifier(max_features='auto',n_estimators=300,max_depth=100,random_state=2,class_weight='balanced')\n",
    "rf3=RandomForestClassifier(max_features='auto',n_estimators=300,max_depth=100,random_state=0,class_weight='balanced')\n",
    "vcrf = VotingClassifier(estimators=[('rf1', rf1), ('rf2', rf2), ('rf3', rf3)], voting='hard')\n",
    "show_score(vcrf,X_train[best_cols], X_test[best_cols], y_train, y_test,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбалансированная выборка + Модель с лучшими колонками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout : 0.627604166667\n",
      "Crossval: 0.87724137931\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(max_features='sqrt',n_estimators=300,max_depth=100,random_state=42)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_sample(X_train,y_train)\n",
    "X_res=pd.DataFrame(X_res,columns=base_col)\n",
    "show_score(rf,X_res[best_cols],X_test[best_cols], y_res, y_test,cv=5)\n",
    "# Holdout : 0.627604166667\n",
    "# Crossval: 0.87724137931"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбалансированная выборка + Усредненная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout : 0.6328125\n",
      "Crossval: 0.874482758621\n"
     ]
    }
   ],
   "source": [
    "rf1=RandomForestClassifier(max_features='auto',n_estimators=300,max_depth=100,random_state=1)\n",
    "rf2=RandomForestClassifier(max_features='auto',n_estimators=300,max_depth=100,random_state=2)\n",
    "rf3=RandomForestClassifier(max_features='auto',n_estimators=300,max_depth=100,random_state=0)\n",
    "vcrf = VotingClassifier(estimators=[('rf1', rf1), ('rf2', rf2), ('rf3', rf3)], voting='hard')\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_sample(X_train,y_train)\n",
    "X_res=pd.DataFrame(X_res,columns=base_col)\n",
    "show_score(vcrf,X_res[best_cols],X_test[best_cols], y_res, y_test,cv=5)\n",
    "#st Holdout : 0.6328125\n",
    "#st Crossval: 0.874482758621"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2337, 223)\n",
      "(2337, 8)\n",
      "(2337, 231)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f221</th>\n",
       "      <th>f222</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>-1.460664</td>\n",
       "      <td>0.563193</td>\n",
       "      <td>1.419713</td>\n",
       "      <td>0.840796</td>\n",
       "      <td>0.836331</td>\n",
       "      <td>2.348731</td>\n",
       "      <td>-1.618840</td>\n",
       "      <td>1.021211</td>\n",
       "      <td>0.370149</td>\n",
       "      <td>3.378404</td>\n",
       "      <td>...</td>\n",
       "      <td>1.237549</td>\n",
       "      <td>0.031998</td>\n",
       "      <td>-37.187678</td>\n",
       "      <td>-4.562100</td>\n",
       "      <td>-4.286233</td>\n",
       "      <td>-31.660545</td>\n",
       "      <td>-35.660244</td>\n",
       "      <td>-7.970558</td>\n",
       "      <td>-15.782790</td>\n",
       "      <td>12.566372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>-0.038166</td>\n",
       "      <td>-2.513906</td>\n",
       "      <td>-2.790534</td>\n",
       "      <td>0.871415</td>\n",
       "      <td>0.095533</td>\n",
       "      <td>1.994102</td>\n",
       "      <td>0.112956</td>\n",
       "      <td>-3.093611</td>\n",
       "      <td>1.929815</td>\n",
       "      <td>2.537634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844416</td>\n",
       "      <td>0.145741</td>\n",
       "      <td>67.420224</td>\n",
       "      <td>-18.169302</td>\n",
       "      <td>7.168478</td>\n",
       "      <td>-7.537953</td>\n",
       "      <td>-41.995476</td>\n",
       "      <td>-9.550631</td>\n",
       "      <td>47.814296</td>\n",
       "      <td>-36.363724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>2.642683</td>\n",
       "      <td>1.938798</td>\n",
       "      <td>0.041850</td>\n",
       "      <td>0.762693</td>\n",
       "      <td>0.451556</td>\n",
       "      <td>-1.004065</td>\n",
       "      <td>3.647878</td>\n",
       "      <td>0.340410</td>\n",
       "      <td>0.763806</td>\n",
       "      <td>4.824045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.448550</td>\n",
       "      <td>1.501773</td>\n",
       "      <td>50.178424</td>\n",
       "      <td>-35.738613</td>\n",
       "      <td>2.123865</td>\n",
       "      <td>-10.325766</td>\n",
       "      <td>4.926490</td>\n",
       "      <td>-33.987918</td>\n",
       "      <td>2.872526</td>\n",
       "      <td>-28.446873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>1.251088</td>\n",
       "      <td>2.036716</td>\n",
       "      <td>2.912373</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>0.887048</td>\n",
       "      <td>0.939330</td>\n",
       "      <td>0.943293</td>\n",
       "      <td>3.153591</td>\n",
       "      <td>0.726129</td>\n",
       "      <td>3.640001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333029</td>\n",
       "      <td>0.847550</td>\n",
       "      <td>-25.160795</td>\n",
       "      <td>-11.856370</td>\n",
       "      <td>-22.556273</td>\n",
       "      <td>-16.214458</td>\n",
       "      <td>-27.840651</td>\n",
       "      <td>-4.661709</td>\n",
       "      <td>-4.560111</td>\n",
       "      <td>-38.947341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>-1.724362</td>\n",
       "      <td>2.600789</td>\n",
       "      <td>2.543875</td>\n",
       "      <td>0.741890</td>\n",
       "      <td>0.684756</td>\n",
       "      <td>0.858326</td>\n",
       "      <td>-2.037829</td>\n",
       "      <td>3.114451</td>\n",
       "      <td>0.227140</td>\n",
       "      <td>5.141027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438190</td>\n",
       "      <td>0.231682</td>\n",
       "      <td>-30.535795</td>\n",
       "      <td>9.072318</td>\n",
       "      <td>-12.200447</td>\n",
       "      <td>-7.183746</td>\n",
       "      <td>-28.204614</td>\n",
       "      <td>-6.291684</td>\n",
       "      <td>-21.677006</td>\n",
       "      <td>-26.699608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>-0.954392</td>\n",
       "      <td>-0.804023</td>\n",
       "      <td>-0.860677</td>\n",
       "      <td>0.498871</td>\n",
       "      <td>0.921235</td>\n",
       "      <td>3.033823</td>\n",
       "      <td>-0.430237</td>\n",
       "      <td>-1.734621</td>\n",
       "      <td>1.413340</td>\n",
       "      <td>1.797144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940318</td>\n",
       "      <td>-0.238219</td>\n",
       "      <td>-2.253112</td>\n",
       "      <td>25.967801</td>\n",
       "      <td>-44.525776</td>\n",
       "      <td>65.294814</td>\n",
       "      <td>14.018769</td>\n",
       "      <td>-61.648328</td>\n",
       "      <td>30.214330</td>\n",
       "      <td>-5.543247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>0.677478</td>\n",
       "      <td>0.722754</td>\n",
       "      <td>1.030661</td>\n",
       "      <td>0.284088</td>\n",
       "      <td>0.659514</td>\n",
       "      <td>1.423222</td>\n",
       "      <td>0.373077</td>\n",
       "      <td>0.594629</td>\n",
       "      <td>1.288414</td>\n",
       "      <td>1.994541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279303</td>\n",
       "      <td>0.065385</td>\n",
       "      <td>24.735796</td>\n",
       "      <td>30.758679</td>\n",
       "      <td>-6.038885</td>\n",
       "      <td>-13.550551</td>\n",
       "      <td>-46.208889</td>\n",
       "      <td>-39.758378</td>\n",
       "      <td>-38.405623</td>\n",
       "      <td>-9.763381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>0.916963</td>\n",
       "      <td>-0.092062</td>\n",
       "      <td>-1.003232</td>\n",
       "      <td>0.217005</td>\n",
       "      <td>0.365511</td>\n",
       "      <td>-1.855290</td>\n",
       "      <td>1.444779</td>\n",
       "      <td>-1.042715</td>\n",
       "      <td>-0.302220</td>\n",
       "      <td>2.960998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>1.121395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.320770</td>\n",
       "      <td>-1.683886</td>\n",
       "      <td>-1.286806</td>\n",
       "      <td>0.195577</td>\n",
       "      <td>0.464381</td>\n",
       "      <td>1.233878</td>\n",
       "      <td>-0.356704</td>\n",
       "      <td>-1.919804</td>\n",
       "      <td>0.308680</td>\n",
       "      <td>0.920075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742037</td>\n",
       "      <td>0.596289</td>\n",
       "      <td>-26.959634</td>\n",
       "      <td>32.266709</td>\n",
       "      <td>81.751030</td>\n",
       "      <td>5.965907</td>\n",
       "      <td>32.741232</td>\n",
       "      <td>27.295696</td>\n",
       "      <td>18.378400</td>\n",
       "      <td>-4.437917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>-0.970513</td>\n",
       "      <td>0.752263</td>\n",
       "      <td>0.682730</td>\n",
       "      <td>0.731552</td>\n",
       "      <td>0.800870</td>\n",
       "      <td>0.183587</td>\n",
       "      <td>-1.139633</td>\n",
       "      <td>1.287314</td>\n",
       "      <td>-0.407099</td>\n",
       "      <td>2.622624</td>\n",
       "      <td>...</td>\n",
       "      <td>1.188553</td>\n",
       "      <td>0.746109</td>\n",
       "      <td>-4.276853</td>\n",
       "      <td>-20.695670</td>\n",
       "      <td>-17.655073</td>\n",
       "      <td>-9.262397</td>\n",
       "      <td>16.712468</td>\n",
       "      <td>-21.378599</td>\n",
       "      <td>-12.588961</td>\n",
       "      <td>-38.667101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2.100019</td>\n",
       "      <td>-2.248651</td>\n",
       "      <td>-2.877757</td>\n",
       "      <td>0.411856</td>\n",
       "      <td>0.520608</td>\n",
       "      <td>0.059903</td>\n",
       "      <td>2.792895</td>\n",
       "      <td>-2.234537</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>5.854663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988093</td>\n",
       "      <td>1.252776</td>\n",
       "      <td>5.621122</td>\n",
       "      <td>-45.290509</td>\n",
       "      <td>-26.759751</td>\n",
       "      <td>-18.968833</td>\n",
       "      <td>-4.152750</td>\n",
       "      <td>-16.804530</td>\n",
       "      <td>31.496200</td>\n",
       "      <td>9.152895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>0.162379</td>\n",
       "      <td>1.350160</td>\n",
       "      <td>1.804701</td>\n",
       "      <td>0.136253</td>\n",
       "      <td>0.455568</td>\n",
       "      <td>-0.101781</td>\n",
       "      <td>-0.411859</td>\n",
       "      <td>1.429387</td>\n",
       "      <td>-0.176081</td>\n",
       "      <td>3.725412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124940</td>\n",
       "      <td>0.266027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>-0.755025</td>\n",
       "      <td>2.574440</td>\n",
       "      <td>2.930760</td>\n",
       "      <td>0.581396</td>\n",
       "      <td>0.707067</td>\n",
       "      <td>3.613900</td>\n",
       "      <td>-0.743321</td>\n",
       "      <td>3.571536</td>\n",
       "      <td>0.489005</td>\n",
       "      <td>3.311236</td>\n",
       "      <td>...</td>\n",
       "      <td>1.232873</td>\n",
       "      <td>0.095171</td>\n",
       "      <td>-21.583351</td>\n",
       "      <td>-24.091823</td>\n",
       "      <td>6.525934</td>\n",
       "      <td>-11.375506</td>\n",
       "      <td>-33.049516</td>\n",
       "      <td>11.090129</td>\n",
       "      <td>10.905334</td>\n",
       "      <td>-6.429917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>-1.299120</td>\n",
       "      <td>2.072345</td>\n",
       "      <td>2.505518</td>\n",
       "      <td>0.068195</td>\n",
       "      <td>0.931232</td>\n",
       "      <td>2.878607</td>\n",
       "      <td>-1.343140</td>\n",
       "      <td>2.730226</td>\n",
       "      <td>0.291252</td>\n",
       "      <td>0.884269</td>\n",
       "      <td>...</td>\n",
       "      <td>1.228409</td>\n",
       "      <td>0.084611</td>\n",
       "      <td>-59.350406</td>\n",
       "      <td>-126.302357</td>\n",
       "      <td>-55.260807</td>\n",
       "      <td>105.789034</td>\n",
       "      <td>104.669551</td>\n",
       "      <td>314.833322</td>\n",
       "      <td>47.908806</td>\n",
       "      <td>141.418263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>2.152353</td>\n",
       "      <td>-0.215729</td>\n",
       "      <td>0.206642</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.739468</td>\n",
       "      <td>-1.461599</td>\n",
       "      <td>3.584539</td>\n",
       "      <td>0.365618</td>\n",
       "      <td>0.832802</td>\n",
       "      <td>5.263525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082386</td>\n",
       "      <td>1.348792</td>\n",
       "      <td>-11.580224</td>\n",
       "      <td>-25.290038</td>\n",
       "      <td>-13.621851</td>\n",
       "      <td>-21.896926</td>\n",
       "      <td>-26.724343</td>\n",
       "      <td>-40.870462</td>\n",
       "      <td>72.744152</td>\n",
       "      <td>7.498739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>2.224742</td>\n",
       "      <td>-1.935866</td>\n",
       "      <td>-3.128125</td>\n",
       "      <td>0.812934</td>\n",
       "      <td>0.207383</td>\n",
       "      <td>-0.842583</td>\n",
       "      <td>2.309060</td>\n",
       "      <td>-3.123256</td>\n",
       "      <td>0.068938</td>\n",
       "      <td>5.935442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764057</td>\n",
       "      <td>0.508754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>2.742366</td>\n",
       "      <td>0.768805</td>\n",
       "      <td>0.430435</td>\n",
       "      <td>0.593358</td>\n",
       "      <td>0.426055</td>\n",
       "      <td>-3.027177</td>\n",
       "      <td>3.561133</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.296618</td>\n",
       "      <td>0.524647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.562004</td>\n",
       "      <td>0.793969</td>\n",
       "      <td>114.854552</td>\n",
       "      <td>-10.291224</td>\n",
       "      <td>46.748387</td>\n",
       "      <td>56.350790</td>\n",
       "      <td>-37.536357</td>\n",
       "      <td>27.880678</td>\n",
       "      <td>-11.444770</td>\n",
       "      <td>-64.046662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>1.079662</td>\n",
       "      <td>0.948626</td>\n",
       "      <td>1.679622</td>\n",
       "      <td>0.657523</td>\n",
       "      <td>0.031406</td>\n",
       "      <td>-0.418658</td>\n",
       "      <td>0.282432</td>\n",
       "      <td>0.992969</td>\n",
       "      <td>0.435686</td>\n",
       "      <td>1.130470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570356</td>\n",
       "      <td>0.572440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>-0.715354</td>\n",
       "      <td>-1.872944</td>\n",
       "      <td>-2.063130</td>\n",
       "      <td>0.101823</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>1.306396</td>\n",
       "      <td>-1.288843</td>\n",
       "      <td>-2.143067</td>\n",
       "      <td>0.196957</td>\n",
       "      <td>0.590917</td>\n",
       "      <td>...</td>\n",
       "      <td>1.213050</td>\n",
       "      <td>-0.112342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>2.013859</td>\n",
       "      <td>-2.659920</td>\n",
       "      <td>-3.435256</td>\n",
       "      <td>0.657722</td>\n",
       "      <td>0.936732</td>\n",
       "      <td>-0.732703</td>\n",
       "      <td>1.577130</td>\n",
       "      <td>-3.053097</td>\n",
       "      <td>0.231143</td>\n",
       "      <td>4.574869</td>\n",
       "      <td>...</td>\n",
       "      <td>1.077485</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>498.940908</td>\n",
       "      <td>29.840880</td>\n",
       "      <td>-39.885599</td>\n",
       "      <td>121.791856</td>\n",
       "      <td>-80.507002</td>\n",
       "      <td>47.381332</td>\n",
       "      <td>-20.380114</td>\n",
       "      <td>-62.752707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>-0.698340</td>\n",
       "      <td>0.513360</td>\n",
       "      <td>0.759460</td>\n",
       "      <td>0.186163</td>\n",
       "      <td>0.584508</td>\n",
       "      <td>3.215664</td>\n",
       "      <td>-1.785702</td>\n",
       "      <td>1.387132</td>\n",
       "      <td>0.195701</td>\n",
       "      <td>0.502902</td>\n",
       "      <td>...</td>\n",
       "      <td>1.831335</td>\n",
       "      <td>-0.110629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>0.092577</td>\n",
       "      <td>-2.172802</td>\n",
       "      <td>-3.448061</td>\n",
       "      <td>0.174485</td>\n",
       "      <td>0.196535</td>\n",
       "      <td>3.456048</td>\n",
       "      <td>0.300484</td>\n",
       "      <td>-3.039287</td>\n",
       "      <td>0.792315</td>\n",
       "      <td>6.631734</td>\n",
       "      <td>...</td>\n",
       "      <td>2.231532</td>\n",
       "      <td>0.265199</td>\n",
       "      <td>20.754815</td>\n",
       "      <td>4.017389</td>\n",
       "      <td>-1.692869</td>\n",
       "      <td>-11.187736</td>\n",
       "      <td>0.844569</td>\n",
       "      <td>2.056922</td>\n",
       "      <td>-19.836829</td>\n",
       "      <td>-35.932638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>1.488098</td>\n",
       "      <td>0.944618</td>\n",
       "      <td>1.701003</td>\n",
       "      <td>0.672996</td>\n",
       "      <td>0.443032</td>\n",
       "      <td>-2.553181</td>\n",
       "      <td>1.515738</td>\n",
       "      <td>2.058113</td>\n",
       "      <td>-0.216748</td>\n",
       "      <td>2.419852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543855</td>\n",
       "      <td>0.286999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>2.070607</td>\n",
       "      <td>1.251306</td>\n",
       "      <td>0.858798</td>\n",
       "      <td>0.672278</td>\n",
       "      <td>0.262514</td>\n",
       "      <td>-1.038741</td>\n",
       "      <td>1.694078</td>\n",
       "      <td>0.749350</td>\n",
       "      <td>0.560959</td>\n",
       "      <td>2.950503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075608</td>\n",
       "      <td>1.100309</td>\n",
       "      <td>19.422250</td>\n",
       "      <td>-95.183813</td>\n",
       "      <td>-72.154978</td>\n",
       "      <td>-69.546182</td>\n",
       "      <td>127.097197</td>\n",
       "      <td>-86.093253</td>\n",
       "      <td>-48.005324</td>\n",
       "      <td>-26.488251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2.555129</td>\n",
       "      <td>0.187027</td>\n",
       "      <td>-0.317524</td>\n",
       "      <td>0.520061</td>\n",
       "      <td>0.434421</td>\n",
       "      <td>-2.602058</td>\n",
       "      <td>3.244282</td>\n",
       "      <td>-0.118415</td>\n",
       "      <td>0.426237</td>\n",
       "      <td>4.237288</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.107009</td>\n",
       "      <td>1.341015</td>\n",
       "      <td>-35.122493</td>\n",
       "      <td>-38.850665</td>\n",
       "      <td>107.687414</td>\n",
       "      <td>58.587279</td>\n",
       "      <td>39.764499</td>\n",
       "      <td>-41.148583</td>\n",
       "      <td>-10.740440</td>\n",
       "      <td>-64.210182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.335698</td>\n",
       "      <td>2.838515</td>\n",
       "      <td>3.821535</td>\n",
       "      <td>0.155084</td>\n",
       "      <td>0.049621</td>\n",
       "      <td>3.368388</td>\n",
       "      <td>-0.176973</td>\n",
       "      <td>4.461507</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>6.088674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493902</td>\n",
       "      <td>0.118181</td>\n",
       "      <td>-21.417820</td>\n",
       "      <td>104.860992</td>\n",
       "      <td>30.890699</td>\n",
       "      <td>-69.775258</td>\n",
       "      <td>52.872569</td>\n",
       "      <td>75.462836</td>\n",
       "      <td>56.270284</td>\n",
       "      <td>24.790283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>-1.225815</td>\n",
       "      <td>-1.680547</td>\n",
       "      <td>-1.870873</td>\n",
       "      <td>0.745778</td>\n",
       "      <td>0.274660</td>\n",
       "      <td>1.732726</td>\n",
       "      <td>-0.782996</td>\n",
       "      <td>-2.157356</td>\n",
       "      <td>0.491157</td>\n",
       "      <td>6.158058</td>\n",
       "      <td>...</td>\n",
       "      <td>1.181376</td>\n",
       "      <td>-0.272256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>-1.320599</td>\n",
       "      <td>0.447537</td>\n",
       "      <td>0.438177</td>\n",
       "      <td>0.312942</td>\n",
       "      <td>0.509279</td>\n",
       "      <td>0.362073</td>\n",
       "      <td>-1.062243</td>\n",
       "      <td>0.282377</td>\n",
       "      <td>0.555751</td>\n",
       "      <td>1.870459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181343</td>\n",
       "      <td>-0.122914</td>\n",
       "      <td>12.440849</td>\n",
       "      <td>-61.718775</td>\n",
       "      <td>-20.572692</td>\n",
       "      <td>-44.658448</td>\n",
       "      <td>92.658313</td>\n",
       "      <td>-59.535056</td>\n",
       "      <td>-30.149319</td>\n",
       "      <td>-12.868166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>1.892392</td>\n",
       "      <td>-0.082555</td>\n",
       "      <td>-0.867167</td>\n",
       "      <td>0.215715</td>\n",
       "      <td>0.171420</td>\n",
       "      <td>-3.935631</td>\n",
       "      <td>3.139699</td>\n",
       "      <td>-0.508197</td>\n",
       "      <td>-0.085120</td>\n",
       "      <td>1.989085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275529</td>\n",
       "      <td>0.673906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.007539</td>\n",
       "      <td>-2.650239</td>\n",
       "      <td>-2.934310</td>\n",
       "      <td>0.678864</td>\n",
       "      <td>0.444406</td>\n",
       "      <td>0.191869</td>\n",
       "      <td>0.584481</td>\n",
       "      <td>-3.155137</td>\n",
       "      <td>0.501938</td>\n",
       "      <td>3.107410</td>\n",
       "      <td>...</td>\n",
       "      <td>1.282462</td>\n",
       "      <td>-0.015853</td>\n",
       "      <td>-58.920304</td>\n",
       "      <td>-14.397391</td>\n",
       "      <td>152.012305</td>\n",
       "      <td>179.317643</td>\n",
       "      <td>68.874068</td>\n",
       "      <td>-33.130559</td>\n",
       "      <td>35.614280</td>\n",
       "      <td>2.562854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>-0.922365</td>\n",
       "      <td>-1.556576</td>\n",
       "      <td>-2.257834</td>\n",
       "      <td>0.464388</td>\n",
       "      <td>0.382574</td>\n",
       "      <td>2.121413</td>\n",
       "      <td>-1.327125</td>\n",
       "      <td>-2.610873</td>\n",
       "      <td>0.620884</td>\n",
       "      <td>3.398402</td>\n",
       "      <td>...</td>\n",
       "      <td>1.561880</td>\n",
       "      <td>-0.357064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>-0.773530</td>\n",
       "      <td>0.590438</td>\n",
       "      <td>1.287345</td>\n",
       "      <td>0.802267</td>\n",
       "      <td>0.514790</td>\n",
       "      <td>1.158761</td>\n",
       "      <td>-0.794757</td>\n",
       "      <td>0.336136</td>\n",
       "      <td>0.112945</td>\n",
       "      <td>2.762612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791197</td>\n",
       "      <td>-0.214993</td>\n",
       "      <td>-32.606121</td>\n",
       "      <td>-30.731630</td>\n",
       "      <td>46.722737</td>\n",
       "      <td>18.212896</td>\n",
       "      <td>14.186839</td>\n",
       "      <td>-17.499853</td>\n",
       "      <td>-18.864502</td>\n",
       "      <td>-60.342689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>1.535460</td>\n",
       "      <td>1.034251</td>\n",
       "      <td>1.457509</td>\n",
       "      <td>0.194937</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>0.095483</td>\n",
       "      <td>1.307816</td>\n",
       "      <td>1.404566</td>\n",
       "      <td>0.271227</td>\n",
       "      <td>3.453778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314292</td>\n",
       "      <td>0.373507</td>\n",
       "      <td>-28.559412</td>\n",
       "      <td>-41.919241</td>\n",
       "      <td>-69.104891</td>\n",
       "      <td>-5.871354</td>\n",
       "      <td>6.774497</td>\n",
       "      <td>74.235379</td>\n",
       "      <td>1.838732</td>\n",
       "      <td>2.326320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>0.056967</td>\n",
       "      <td>2.433041</td>\n",
       "      <td>3.083191</td>\n",
       "      <td>0.752048</td>\n",
       "      <td>0.212143</td>\n",
       "      <td>1.134389</td>\n",
       "      <td>-0.611901</td>\n",
       "      <td>3.882780</td>\n",
       "      <td>0.308963</td>\n",
       "      <td>0.681986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204578</td>\n",
       "      <td>0.487526</td>\n",
       "      <td>-23.100314</td>\n",
       "      <td>-15.208134</td>\n",
       "      <td>-25.973680</td>\n",
       "      <td>-22.883653</td>\n",
       "      <td>-20.959183</td>\n",
       "      <td>-18.583020</td>\n",
       "      <td>-40.096432</td>\n",
       "      <td>-11.759425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1.317070</td>\n",
       "      <td>1.876920</td>\n",
       "      <td>2.069449</td>\n",
       "      <td>-0.016912</td>\n",
       "      <td>0.180494</td>\n",
       "      <td>1.043509</td>\n",
       "      <td>0.818723</td>\n",
       "      <td>2.098991</td>\n",
       "      <td>0.599545</td>\n",
       "      <td>4.089465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252487</td>\n",
       "      <td>1.069044</td>\n",
       "      <td>-32.404881</td>\n",
       "      <td>-22.766182</td>\n",
       "      <td>-17.326967</td>\n",
       "      <td>1.118428</td>\n",
       "      <td>-18.548523</td>\n",
       "      <td>46.050572</td>\n",
       "      <td>-4.728832</td>\n",
       "      <td>-16.462145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>0.634959</td>\n",
       "      <td>1.080199</td>\n",
       "      <td>1.083204</td>\n",
       "      <td>0.011944</td>\n",
       "      <td>0.772071</td>\n",
       "      <td>2.161517</td>\n",
       "      <td>1.071948</td>\n",
       "      <td>1.660441</td>\n",
       "      <td>1.014669</td>\n",
       "      <td>4.549234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395322</td>\n",
       "      <td>0.588420</td>\n",
       "      <td>-10.213876</td>\n",
       "      <td>47.754627</td>\n",
       "      <td>-16.177905</td>\n",
       "      <td>-1.817013</td>\n",
       "      <td>-20.900142</td>\n",
       "      <td>8.118685</td>\n",
       "      <td>2.838267</td>\n",
       "      <td>-17.907923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>-1.215452</td>\n",
       "      <td>1.906414</td>\n",
       "      <td>2.537556</td>\n",
       "      <td>0.714519</td>\n",
       "      <td>0.906776</td>\n",
       "      <td>2.485104</td>\n",
       "      <td>-1.247232</td>\n",
       "      <td>3.120770</td>\n",
       "      <td>0.323111</td>\n",
       "      <td>1.491771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349446</td>\n",
       "      <td>-0.297213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>0.265648</td>\n",
       "      <td>1.121018</td>\n",
       "      <td>0.724338</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>0.603320</td>\n",
       "      <td>-0.346800</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.224733</td>\n",
       "      <td>0.459957</td>\n",
       "      <td>3.680991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002075</td>\n",
       "      <td>-0.140992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>-0.292938</td>\n",
       "      <td>0.137649</td>\n",
       "      <td>0.288585</td>\n",
       "      <td>0.373566</td>\n",
       "      <td>0.428141</td>\n",
       "      <td>-1.826066</td>\n",
       "      <td>-0.016782</td>\n",
       "      <td>-0.603881</td>\n",
       "      <td>-0.371082</td>\n",
       "      <td>1.255504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272098</td>\n",
       "      <td>0.351123</td>\n",
       "      <td>112.689400</td>\n",
       "      <td>-54.759923</td>\n",
       "      <td>70.910238</td>\n",
       "      <td>-77.689702</td>\n",
       "      <td>-114.965998</td>\n",
       "      <td>-46.210928</td>\n",
       "      <td>209.840777</td>\n",
       "      <td>90.046588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>2.263796</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>-0.139492</td>\n",
       "      <td>0.030439</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>-4.089712</td>\n",
       "      <td>2.787828</td>\n",
       "      <td>0.647296</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>4.308220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312475</td>\n",
       "      <td>1.307394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.886613</td>\n",
       "      <td>-2.066336</td>\n",
       "      <td>-2.648893</td>\n",
       "      <td>0.557731</td>\n",
       "      <td>0.884662</td>\n",
       "      <td>-0.642934</td>\n",
       "      <td>0.644388</td>\n",
       "      <td>-2.900805</td>\n",
       "      <td>0.835164</td>\n",
       "      <td>0.628255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675525</td>\n",
       "      <td>0.606467</td>\n",
       "      <td>-22.024439</td>\n",
       "      <td>-6.268626</td>\n",
       "      <td>-29.445217</td>\n",
       "      <td>-29.633167</td>\n",
       "      <td>4.314496</td>\n",
       "      <td>14.890439</td>\n",
       "      <td>-20.062777</td>\n",
       "      <td>-13.209668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380</th>\n",
       "      <td>-0.108204</td>\n",
       "      <td>1.431122</td>\n",
       "      <td>2.512820</td>\n",
       "      <td>0.423859</td>\n",
       "      <td>0.767512</td>\n",
       "      <td>-0.607554</td>\n",
       "      <td>0.455355</td>\n",
       "      <td>2.139290</td>\n",
       "      <td>0.484278</td>\n",
       "      <td>2.445399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.475645</td>\n",
       "      <td>0.243231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>-0.313358</td>\n",
       "      <td>2.948484</td>\n",
       "      <td>3.916853</td>\n",
       "      <td>0.530509</td>\n",
       "      <td>0.628124</td>\n",
       "      <td>2.215972</td>\n",
       "      <td>-0.804847</td>\n",
       "      <td>4.025399</td>\n",
       "      <td>1.053513</td>\n",
       "      <td>8.348528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285444</td>\n",
       "      <td>0.258920</td>\n",
       "      <td>-44.034890</td>\n",
       "      <td>53.315979</td>\n",
       "      <td>-62.081022</td>\n",
       "      <td>103.687822</td>\n",
       "      <td>-25.889265</td>\n",
       "      <td>-31.714349</td>\n",
       "      <td>24.272326</td>\n",
       "      <td>5.603732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2.288675</td>\n",
       "      <td>-1.671944</td>\n",
       "      <td>-2.273397</td>\n",
       "      <td>0.313887</td>\n",
       "      <td>0.073042</td>\n",
       "      <td>0.970624</td>\n",
       "      <td>3.000186</td>\n",
       "      <td>-1.974379</td>\n",
       "      <td>1.289683</td>\n",
       "      <td>1.816512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963741</td>\n",
       "      <td>1.553403</td>\n",
       "      <td>-9.192389</td>\n",
       "      <td>49.667166</td>\n",
       "      <td>-31.057991</td>\n",
       "      <td>-1.175169</td>\n",
       "      <td>40.563773</td>\n",
       "      <td>-21.053851</td>\n",
       "      <td>-10.305468</td>\n",
       "      <td>10.291843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>3.292432</td>\n",
       "      <td>-1.790045</td>\n",
       "      <td>-3.455952</td>\n",
       "      <td>0.904297</td>\n",
       "      <td>0.811441</td>\n",
       "      <td>2.444781</td>\n",
       "      <td>3.341091</td>\n",
       "      <td>-3.560244</td>\n",
       "      <td>1.137982</td>\n",
       "      <td>7.155094</td>\n",
       "      <td>...</td>\n",
       "      <td>1.865025</td>\n",
       "      <td>1.012275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>-0.495621</td>\n",
       "      <td>2.987931</td>\n",
       "      <td>3.700792</td>\n",
       "      <td>0.193153</td>\n",
       "      <td>0.573640</td>\n",
       "      <td>3.872243</td>\n",
       "      <td>-1.763921</td>\n",
       "      <td>4.983398</td>\n",
       "      <td>0.404526</td>\n",
       "      <td>0.973304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885597</td>\n",
       "      <td>-0.019446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>1.457413</td>\n",
       "      <td>0.105370</td>\n",
       "      <td>-0.164913</td>\n",
       "      <td>0.017402</td>\n",
       "      <td>0.334794</td>\n",
       "      <td>-2.661552</td>\n",
       "      <td>2.003223</td>\n",
       "      <td>-0.267162</td>\n",
       "      <td>0.461284</td>\n",
       "      <td>0.695955</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075088</td>\n",
       "      <td>0.413623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>3.401297</td>\n",
       "      <td>0.026487</td>\n",
       "      <td>-0.902350</td>\n",
       "      <td>0.416975</td>\n",
       "      <td>0.573602</td>\n",
       "      <td>-2.484567</td>\n",
       "      <td>4.431743</td>\n",
       "      <td>-1.028537</td>\n",
       "      <td>0.146606</td>\n",
       "      <td>0.850991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.809069</td>\n",
       "      <td>1.711681</td>\n",
       "      <td>-40.051195</td>\n",
       "      <td>154.878322</td>\n",
       "      <td>-83.120015</td>\n",
       "      <td>166.481224</td>\n",
       "      <td>63.481273</td>\n",
       "      <td>-101.756884</td>\n",
       "      <td>52.897284</td>\n",
       "      <td>66.315937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>-0.822939</td>\n",
       "      <td>1.663237</td>\n",
       "      <td>2.325111</td>\n",
       "      <td>1.254564</td>\n",
       "      <td>0.093367</td>\n",
       "      <td>2.096959</td>\n",
       "      <td>-1.417431</td>\n",
       "      <td>2.188624</td>\n",
       "      <td>0.262287</td>\n",
       "      <td>3.626110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730178</td>\n",
       "      <td>0.091898</td>\n",
       "      <td>-26.950911</td>\n",
       "      <td>-10.735741</td>\n",
       "      <td>-21.293141</td>\n",
       "      <td>-8.150038</td>\n",
       "      <td>-33.702773</td>\n",
       "      <td>31.500382</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>-20.256296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.804733</td>\n",
       "      <td>1.214984</td>\n",
       "      <td>1.421183</td>\n",
       "      <td>0.104743</td>\n",
       "      <td>0.125182</td>\n",
       "      <td>-2.557195</td>\n",
       "      <td>1.511522</td>\n",
       "      <td>1.636521</td>\n",
       "      <td>-0.051766</td>\n",
       "      <td>4.217016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.645735</td>\n",
       "      <td>0.463991</td>\n",
       "      <td>9.361518</td>\n",
       "      <td>50.661044</td>\n",
       "      <td>-11.462477</td>\n",
       "      <td>-91.607339</td>\n",
       "      <td>110.061627</td>\n",
       "      <td>-23.061780</td>\n",
       "      <td>-13.060825</td>\n",
       "      <td>-9.118840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0.142730</td>\n",
       "      <td>0.834282</td>\n",
       "      <td>0.797314</td>\n",
       "      <td>0.290086</td>\n",
       "      <td>0.709768</td>\n",
       "      <td>-1.525127</td>\n",
       "      <td>0.170110</td>\n",
       "      <td>0.488694</td>\n",
       "      <td>-0.218941</td>\n",
       "      <td>2.163029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571265</td>\n",
       "      <td>0.623001</td>\n",
       "      <td>-14.689381</td>\n",
       "      <td>-19.324633</td>\n",
       "      <td>15.447761</td>\n",
       "      <td>-4.571364</td>\n",
       "      <td>-14.868789</td>\n",
       "      <td>-6.544540</td>\n",
       "      <td>-36.420552</td>\n",
       "      <td>-23.405306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>-0.729142</td>\n",
       "      <td>0.035662</td>\n",
       "      <td>-0.465618</td>\n",
       "      <td>0.300715</td>\n",
       "      <td>0.836654</td>\n",
       "      <td>2.289997</td>\n",
       "      <td>-1.050823</td>\n",
       "      <td>-0.647619</td>\n",
       "      <td>1.611751</td>\n",
       "      <td>6.049196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841931</td>\n",
       "      <td>-0.203593</td>\n",
       "      <td>-27.905386</td>\n",
       "      <td>-41.657242</td>\n",
       "      <td>13.148741</td>\n",
       "      <td>-12.061749</td>\n",
       "      <td>-24.695958</td>\n",
       "      <td>27.307555</td>\n",
       "      <td>-36.579050</td>\n",
       "      <td>54.562207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>1.152873</td>\n",
       "      <td>2.837515</td>\n",
       "      <td>3.551294</td>\n",
       "      <td>0.129305</td>\n",
       "      <td>0.703727</td>\n",
       "      <td>2.070641</td>\n",
       "      <td>1.071905</td>\n",
       "      <td>3.780426</td>\n",
       "      <td>0.221794</td>\n",
       "      <td>3.870827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316170</td>\n",
       "      <td>0.719836</td>\n",
       "      <td>-43.924387</td>\n",
       "      <td>0.666126</td>\n",
       "      <td>-16.736882</td>\n",
       "      <td>-22.082660</td>\n",
       "      <td>-27.638924</td>\n",
       "      <td>15.478676</td>\n",
       "      <td>-9.033074</td>\n",
       "      <td>-18.234175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>-0.704764</td>\n",
       "      <td>1.621920</td>\n",
       "      <td>2.065727</td>\n",
       "      <td>0.473616</td>\n",
       "      <td>0.756779</td>\n",
       "      <td>2.180131</td>\n",
       "      <td>-0.479825</td>\n",
       "      <td>2.397122</td>\n",
       "      <td>0.822116</td>\n",
       "      <td>1.860112</td>\n",
       "      <td>...</td>\n",
       "      <td>1.183480</td>\n",
       "      <td>0.390102</td>\n",
       "      <td>23.816676</td>\n",
       "      <td>-4.585166</td>\n",
       "      <td>-18.874641</td>\n",
       "      <td>11.579936</td>\n",
       "      <td>-31.900726</td>\n",
       "      <td>31.630390</td>\n",
       "      <td>-12.311393</td>\n",
       "      <td>-37.165452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>0.166012</td>\n",
       "      <td>1.196509</td>\n",
       "      <td>1.760351</td>\n",
       "      <td>0.486825</td>\n",
       "      <td>0.152180</td>\n",
       "      <td>1.620641</td>\n",
       "      <td>-0.001958</td>\n",
       "      <td>1.624944</td>\n",
       "      <td>0.321211</td>\n",
       "      <td>5.207406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112882</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1.564853</td>\n",
       "      <td>1.753727</td>\n",
       "      <td>2.465411</td>\n",
       "      <td>0.716310</td>\n",
       "      <td>0.591877</td>\n",
       "      <td>-0.018576</td>\n",
       "      <td>1.498871</td>\n",
       "      <td>1.981841</td>\n",
       "      <td>0.327102</td>\n",
       "      <td>1.326838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234462</td>\n",
       "      <td>0.988844</td>\n",
       "      <td>-26.039599</td>\n",
       "      <td>13.730139</td>\n",
       "      <td>-9.999149</td>\n",
       "      <td>-30.116077</td>\n",
       "      <td>-16.708843</td>\n",
       "      <td>-2.141289</td>\n",
       "      <td>-3.579006</td>\n",
       "      <td>-33.057568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.728400</td>\n",
       "      <td>0.743152</td>\n",
       "      <td>0.215298</td>\n",
       "      <td>0.253048</td>\n",
       "      <td>0.546367</td>\n",
       "      <td>-1.363124</td>\n",
       "      <td>1.575861</td>\n",
       "      <td>0.423047</td>\n",
       "      <td>-0.391573</td>\n",
       "      <td>2.299575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437196</td>\n",
       "      <td>1.172366</td>\n",
       "      <td>1.003998</td>\n",
       "      <td>-19.068106</td>\n",
       "      <td>-15.143109</td>\n",
       "      <td>-17.552731</td>\n",
       "      <td>32.298488</td>\n",
       "      <td>25.153908</td>\n",
       "      <td>-67.336560</td>\n",
       "      <td>78.885060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>-0.905785</td>\n",
       "      <td>-0.295737</td>\n",
       "      <td>-1.196420</td>\n",
       "      <td>0.661090</td>\n",
       "      <td>0.325964</td>\n",
       "      <td>-0.251718</td>\n",
       "      <td>-1.195607</td>\n",
       "      <td>-0.903462</td>\n",
       "      <td>0.559753</td>\n",
       "      <td>1.566328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497636</td>\n",
       "      <td>0.210480</td>\n",
       "      <td>-30.713848</td>\n",
       "      <td>-32.695402</td>\n",
       "      <td>9.772455</td>\n",
       "      <td>0.411374</td>\n",
       "      <td>13.085887</td>\n",
       "      <td>93.542614</td>\n",
       "      <td>8.997108</td>\n",
       "      <td>83.819632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1.563612</td>\n",
       "      <td>1.636231</td>\n",
       "      <td>0.956614</td>\n",
       "      <td>0.483613</td>\n",
       "      <td>0.003586</td>\n",
       "      <td>-1.431794</td>\n",
       "      <td>1.592023</td>\n",
       "      <td>1.356712</td>\n",
       "      <td>-0.134481</td>\n",
       "      <td>1.330410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124886</td>\n",
       "      <td>0.753714</td>\n",
       "      <td>-28.995330</td>\n",
       "      <td>32.983805</td>\n",
       "      <td>34.804935</td>\n",
       "      <td>-22.718831</td>\n",
       "      <td>18.332823</td>\n",
       "      <td>23.096483</td>\n",
       "      <td>-10.310306</td>\n",
       "      <td>-21.724621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>0.755790</td>\n",
       "      <td>-2.205241</td>\n",
       "      <td>-2.327994</td>\n",
       "      <td>0.176017</td>\n",
       "      <td>0.805416</td>\n",
       "      <td>-0.174881</td>\n",
       "      <td>0.180964</td>\n",
       "      <td>-2.928835</td>\n",
       "      <td>-0.037015</td>\n",
       "      <td>6.053232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942390</td>\n",
       "      <td>0.333039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2337 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f0        f1        f2        f3        f4        f5        f6  \\\n",
       "1780 -1.460664  0.563193  1.419713  0.840796  0.836331  2.348731 -1.618840   \n",
       "1395 -0.038166 -2.513906 -2.790534  0.871415  0.095533  1.994102  0.112956   \n",
       "237   2.642683  1.938798  0.041850  0.762693  0.451556 -1.004065  3.647878   \n",
       "1161  1.251088  2.036716  2.912373  0.338900  0.887048  0.939330  0.943293   \n",
       "2117 -1.724362  2.600789  2.543875  0.741890  0.684756  0.858326 -2.037829   \n",
       "1133 -0.954392 -0.804023 -0.860677  0.498871  0.921235  3.033823 -0.430237   \n",
       "2288  0.677478  0.722754  1.030661  0.284088  0.659514  1.423222  0.373077   \n",
       "2398  0.916963 -0.092062 -1.003232  0.217005  0.365511 -1.855290  1.444779   \n",
       "163  -0.320770 -1.683886 -1.286806  0.195577  0.464381  1.233878 -0.356704   \n",
       "1422 -0.970513  0.752263  0.682730  0.731552  0.800870  0.183587 -1.139633   \n",
       "252   2.100019 -2.248651 -2.877757  0.411856  0.520608  0.059903  2.792895   \n",
       "3075  0.162379  1.350160  1.804701  0.136253  0.455568 -0.101781 -0.411859   \n",
       "2090 -0.755025  2.574440  2.930760  0.581396  0.707067  3.613900 -0.743321   \n",
       "930  -1.299120  2.072345  2.505518  0.068195  0.931232  2.878607 -1.343140   \n",
       "1569  2.152353 -0.215729  0.206642  0.004921  0.739468 -1.461599  3.584539   \n",
       "3314  2.224742 -1.935866 -3.128125  0.812934  0.207383 -0.842583  2.309060   \n",
       "1608  2.742366  0.768805  0.430435  0.593358  0.426055 -3.027177  3.561133   \n",
       "3419  1.079662  0.948626  1.679622  0.657523  0.031406 -0.418658  0.282432   \n",
       "3300 -0.715354 -1.872944 -2.063130  0.101823  0.000504  1.306396 -1.288843   \n",
       "1866  2.013859 -2.659920 -3.435256  0.657722  0.936732 -0.732703  1.577130   \n",
       "2377 -0.698340  0.513360  0.759460  0.186163  0.584508  3.215664 -1.785702   \n",
       "1090  0.092577 -2.172802 -3.448061  0.174485  0.196535  3.456048  0.300484   \n",
       "2789  1.488098  0.944618  1.701003  0.672996  0.443032 -2.553181  1.515738   \n",
       "593   2.070607  1.251306  0.858798  0.672278  0.262514 -1.038741  1.694078   \n",
       "677   2.555129  0.187027 -0.317524  0.520061  0.434421 -2.602058  3.244282   \n",
       "41    0.335698  2.838515  3.821535  0.155084  0.049621  3.368388 -0.176973   \n",
       "2421 -1.225815 -1.680547 -1.870873  0.745778  0.274660  1.732726 -0.782996   \n",
       "1392 -1.320599  0.447537  0.438177  0.312942  0.509279  0.362073 -1.062243   \n",
       "2784  1.892392 -0.082555 -0.867167  0.215715  0.171420 -3.935631  3.139699   \n",
       "243   0.007539 -2.650239 -2.934310  0.678864  0.444406  0.191869  0.584481   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3385 -0.922365 -1.556576 -2.257834  0.464388  0.382574  2.121413 -1.327125   \n",
       "459  -0.773530  0.590438  1.287345  0.802267  0.514790  1.158761 -0.794757   \n",
       "1184  1.535460  1.034251  1.457509  0.194937  0.517965  0.095483  1.307816   \n",
       "2324  0.056967  2.433041  3.083191  0.752048  0.212143  1.134389 -0.611901   \n",
       "955   1.317070  1.876920  2.069449 -0.016912  0.180494  1.043509  0.818723   \n",
       "1215  0.634959  1.080199  1.083204  0.011944  0.772071  2.161517  1.071948   \n",
       "2433 -1.215452  1.906414  2.537556  0.714519  0.906776  2.485104 -1.247232   \n",
       "2853  0.265648  1.121018  0.724338  0.364793  0.603320 -0.346800  0.014492   \n",
       "1515 -0.292938  0.137649  0.288585  0.373566  0.428141 -1.826066 -0.016782   \n",
       "2391  2.263796  0.024383 -0.139492  0.030439  0.028168 -4.089712  2.787828   \n",
       "769   0.886613 -2.066336 -2.648893  0.557731  0.884662 -0.642934  0.644388   \n",
       "3380 -0.108204  1.431122  2.512820  0.423859  0.767512 -0.607554  0.455355   \n",
       "1685 -0.313358  2.948484  3.916853  0.530509  0.628124  2.215972 -0.804847   \n",
       "130   2.288675 -1.671944 -2.273397  0.313887  0.073042  0.970624  3.000186   \n",
       "2919  3.292432 -1.790045 -3.455952  0.904297  0.811441  2.444781  3.341091   \n",
       "3171 -0.495621  2.987931  3.700792  0.193153  0.573640  3.872243 -1.763921   \n",
       "3444  1.457413  0.105370 -0.164913  0.017402  0.334794 -2.661552  2.003223   \n",
       "2135  3.401297  0.026487 -0.902350  0.416975  0.573602 -2.484567  4.431743   \n",
       "1482 -0.822939  1.663237  2.325111  1.254564  0.093367  2.096959 -1.417431   \n",
       "330   1.804733  1.214984  1.421183  0.104743  0.125182 -2.557195  1.511522   \n",
       "1238  0.142730  0.834282  0.797314  0.290086  0.709768 -1.525127  0.170110   \n",
       "466  -0.729142  0.035662 -0.465618  0.300715  0.836654  2.289997 -1.050823   \n",
       "2169  1.152873  2.837515  3.551294  0.129305  0.703727  2.070641  1.071905   \n",
       "1638 -0.704764  1.621920  2.065727  0.473616  0.756779  2.180131 -0.479825   \n",
       "3092  0.166012  1.196509  1.760351  0.486825  0.152180  1.620641 -0.001958   \n",
       "1095  1.564853  1.753727  2.465411  0.716310  0.591877 -0.018576  1.498871   \n",
       "1130  0.728400  0.743152  0.215298  0.253048  0.546367 -1.363124  1.575861   \n",
       "1294 -0.905785 -0.295737 -1.196420  0.661090  0.325964 -0.251718 -1.195607   \n",
       "860   1.563612  1.636231  0.956614  0.483613  0.003586 -1.431794  1.592023   \n",
       "3174  0.755790 -2.205241 -2.327994  0.176017  0.805416 -0.174881  0.180964   \n",
       "\n",
       "            f7        f8        f9     ...          f221      f222  \\\n",
       "1780  1.021211  0.370149  3.378404     ...      1.237549  0.031998   \n",
       "1395 -3.093611  1.929815  2.537634     ...      0.844416  0.145741   \n",
       "237   0.340410  0.763806  4.824045     ...     -0.448550  1.501773   \n",
       "1161  3.153591  0.726129  3.640001     ...      0.333029  0.847550   \n",
       "2117  3.114451  0.227140  5.141027     ...      0.438190  0.231682   \n",
       "1133 -1.734621  1.413340  1.797144     ...      0.940318 -0.238219   \n",
       "2288  0.594629  1.288414  1.994541     ...      0.279303  0.065385   \n",
       "2398 -1.042715 -0.302220  2.960998     ...      0.178241  1.121395   \n",
       "163  -1.919804  0.308680  0.920075     ...      0.742037  0.596289   \n",
       "1422  1.287314 -0.407099  2.622624     ...      1.188553  0.746109   \n",
       "252  -2.234537  0.455450  5.854663     ...      0.988093  1.252776   \n",
       "3075  1.429387 -0.176081  3.725412     ...      0.124940  0.266027   \n",
       "2090  3.571536  0.489005  3.311236     ...      1.232873  0.095171   \n",
       "930   2.730226  0.291252  0.884269     ...      1.228409  0.084611   \n",
       "1569  0.365618  0.832802  5.263525     ...     -0.082386  1.348792   \n",
       "3314 -3.123256  0.068938  5.935442     ...      0.764057  0.508754   \n",
       "1608  0.022556  0.296618  0.524647     ...     -0.562004  0.793969   \n",
       "3419  0.992969  0.435686  1.130470     ...      0.570356  0.572440   \n",
       "3300 -2.143067  0.196957  0.590917     ...      1.213050 -0.112342   \n",
       "1866 -3.053097  0.231143  4.574869     ...      1.077485  0.977423   \n",
       "2377  1.387132  0.195701  0.502902     ...      1.831335 -0.110629   \n",
       "1090 -3.039287  0.792315  6.631734     ...      2.231532  0.265199   \n",
       "2789  2.058113 -0.216748  2.419852     ...     -0.543855  0.286999   \n",
       "593   0.749350  0.560959  2.950503     ...      0.075608  1.100309   \n",
       "677  -0.118415  0.426237  4.237288     ...     -1.107009  1.341015   \n",
       "41    4.461507  0.293510  6.088674     ...      0.493902  0.118181   \n",
       "2421 -2.157356  0.491157  6.158058     ...      1.181376 -0.272256   \n",
       "1392  0.282377  0.555751  1.870459     ...      0.181343 -0.122914   \n",
       "2784 -0.508197 -0.085120  1.989085     ...     -0.275529  0.673906   \n",
       "243  -3.155137  0.501938  3.107410     ...      1.282462 -0.015853   \n",
       "...        ...       ...       ...     ...           ...       ...   \n",
       "3385 -2.610873  0.620884  3.398402     ...      1.561880 -0.357064   \n",
       "459   0.336136  0.112945  2.762612     ...      0.791197 -0.214993   \n",
       "1184  1.404566  0.271227  3.453778     ...      0.314292  0.373507   \n",
       "2324  3.882780  0.308963  0.681986     ...      0.204578  0.487526   \n",
       "955   2.098991  0.599545  4.089465     ...      0.252487  1.069044   \n",
       "1215  1.660441  1.014669  4.549234     ...      0.395322  0.588420   \n",
       "2433  3.120770  0.323111  1.491771     ...      0.349446 -0.297213   \n",
       "2853  0.224733  0.459957  3.680991     ...     -0.002075 -0.140992   \n",
       "1515 -0.603881 -0.371082  1.255504     ...      0.272098  0.351123   \n",
       "2391  0.647296  0.545455  4.308220     ...     -0.312475  1.307394   \n",
       "769  -2.900805  0.835164  0.628255     ...      0.675525  0.606467   \n",
       "3380  2.139290  0.484278  2.445399     ...     -0.475645  0.243231   \n",
       "1685  4.025399  1.053513  8.348528     ...      0.285444  0.258920   \n",
       "130  -1.974379  1.289683  1.816512     ...      0.963741  1.553403   \n",
       "2919 -3.560244  1.137982  7.155094     ...      1.865025  1.012275   \n",
       "3171  4.983398  0.404526  0.973304     ...      0.885597 -0.019446   \n",
       "3444 -0.267162  0.461284  0.695955     ...     -0.075088  0.413623   \n",
       "2135 -1.028537  0.146606  0.850991     ...     -0.809069  1.711681   \n",
       "1482  2.188624  0.262287  3.626110     ...      0.730178  0.091898   \n",
       "330   1.636521 -0.051766  4.217016     ...     -0.645735  0.463991   \n",
       "1238  0.488694 -0.218941  2.163029     ...     -0.571265  0.623001   \n",
       "466  -0.647619  1.611751  6.049196     ...      0.841931 -0.203593   \n",
       "2169  3.780426  0.221794  3.870827     ...      0.316170  0.719836   \n",
       "1638  2.397122  0.822116  1.860112     ...      1.183480  0.390102   \n",
       "3092  1.624944  0.321211  5.207406     ...      0.112882  0.002648   \n",
       "1095  1.981841  0.327102  1.326838     ...      0.234462  0.988844   \n",
       "1130  0.423047 -0.391573  2.299575     ...      0.437196  1.172366   \n",
       "1294 -0.903462  0.559753  1.566328     ...      0.497636  0.210480   \n",
       "860   1.356712 -0.134481  1.330410     ...      0.124886  0.753714   \n",
       "3174 -2.928835 -0.037015  6.053232     ...      0.942390  0.333039   \n",
       "\n",
       "               0           1           2           3           4           5  \\\n",
       "1780  -37.187678   -4.562100   -4.286233  -31.660545  -35.660244   -7.970558   \n",
       "1395   67.420224  -18.169302    7.168478   -7.537953  -41.995476   -9.550631   \n",
       "237    50.178424  -35.738613    2.123865  -10.325766    4.926490  -33.987918   \n",
       "1161  -25.160795  -11.856370  -22.556273  -16.214458  -27.840651   -4.661709   \n",
       "2117  -30.535795    9.072318  -12.200447   -7.183746  -28.204614   -6.291684   \n",
       "1133   -2.253112   25.967801  -44.525776   65.294814   14.018769  -61.648328   \n",
       "2288   24.735796   30.758679   -6.038885  -13.550551  -46.208889  -39.758378   \n",
       "2398         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "163   -26.959634   32.266709   81.751030    5.965907   32.741232   27.295696   \n",
       "1422   -4.276853  -20.695670  -17.655073   -9.262397   16.712468  -21.378599   \n",
       "252     5.621122  -45.290509  -26.759751  -18.968833   -4.152750  -16.804530   \n",
       "3075         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2090  -21.583351  -24.091823    6.525934  -11.375506  -33.049516   11.090129   \n",
       "930   -59.350406 -126.302357  -55.260807  105.789034  104.669551  314.833322   \n",
       "1569  -11.580224  -25.290038  -13.621851  -21.896926  -26.724343  -40.870462   \n",
       "3314         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1608  114.854552  -10.291224   46.748387   56.350790  -37.536357   27.880678   \n",
       "3419         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3300         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1866  498.940908   29.840880  -39.885599  121.791856  -80.507002   47.381332   \n",
       "2377         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1090   20.754815    4.017389   -1.692869  -11.187736    0.844569    2.056922   \n",
       "2789         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "593    19.422250  -95.183813  -72.154978  -69.546182  127.097197  -86.093253   \n",
       "677   -35.122493  -38.850665  107.687414   58.587279   39.764499  -41.148583   \n",
       "41    -21.417820  104.860992   30.890699  -69.775258   52.872569   75.462836   \n",
       "2421         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1392   12.440849  -61.718775  -20.572692  -44.658448   92.658313  -59.535056   \n",
       "2784         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "243   -58.920304  -14.397391  152.012305  179.317643   68.874068  -33.130559   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3385         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "459   -32.606121  -30.731630   46.722737   18.212896   14.186839  -17.499853   \n",
       "1184  -28.559412  -41.919241  -69.104891   -5.871354    6.774497   74.235379   \n",
       "2324  -23.100314  -15.208134  -25.973680  -22.883653  -20.959183  -18.583020   \n",
       "955   -32.404881  -22.766182  -17.326967    1.118428  -18.548523   46.050572   \n",
       "1215  -10.213876   47.754627  -16.177905   -1.817013  -20.900142    8.118685   \n",
       "2433         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2853         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1515  112.689400  -54.759923   70.910238  -77.689702 -114.965998  -46.210928   \n",
       "2391         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "769   -22.024439   -6.268626  -29.445217  -29.633167    4.314496   14.890439   \n",
       "3380         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1685  -44.034890   53.315979  -62.081022  103.687822  -25.889265  -31.714349   \n",
       "130    -9.192389   49.667166  -31.057991   -1.175169   40.563773  -21.053851   \n",
       "2919         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3171         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3444         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2135  -40.051195  154.878322  -83.120015  166.481224   63.481273 -101.756884   \n",
       "1482  -26.950911  -10.735741  -21.293141   -8.150038  -33.702773   31.500382   \n",
       "330     9.361518   50.661044  -11.462477  -91.607339  110.061627  -23.061780   \n",
       "1238  -14.689381  -19.324633   15.447761   -4.571364  -14.868789   -6.544540   \n",
       "466   -27.905386  -41.657242   13.148741  -12.061749  -24.695958   27.307555   \n",
       "2169  -43.924387    0.666126  -16.736882  -22.082660  -27.638924   15.478676   \n",
       "1638   23.816676   -4.585166  -18.874641   11.579936  -31.900726   31.630390   \n",
       "3092         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1095  -26.039599   13.730139   -9.999149  -30.116077  -16.708843   -2.141289   \n",
       "1130    1.003998  -19.068106  -15.143109  -17.552731   32.298488   25.153908   \n",
       "1294  -30.713848  -32.695402    9.772455    0.411374   13.085887   93.542614   \n",
       "860   -28.995330   32.983805   34.804935  -22.718831   18.332823   23.096483   \n",
       "3174         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "               6           7  \n",
       "1780  -15.782790   12.566372  \n",
       "1395   47.814296  -36.363724  \n",
       "237     2.872526  -28.446873  \n",
       "1161   -4.560111  -38.947341  \n",
       "2117  -21.677006  -26.699608  \n",
       "1133   30.214330   -5.543247  \n",
       "2288  -38.405623   -9.763381  \n",
       "2398         NaN         NaN  \n",
       "163    18.378400   -4.437917  \n",
       "1422  -12.588961  -38.667101  \n",
       "252    31.496200    9.152895  \n",
       "3075         NaN         NaN  \n",
       "2090   10.905334   -6.429917  \n",
       "930    47.908806  141.418263  \n",
       "1569   72.744152    7.498739  \n",
       "3314         NaN         NaN  \n",
       "1608  -11.444770  -64.046662  \n",
       "3419         NaN         NaN  \n",
       "3300         NaN         NaN  \n",
       "1866  -20.380114  -62.752707  \n",
       "2377         NaN         NaN  \n",
       "1090  -19.836829  -35.932638  \n",
       "2789         NaN         NaN  \n",
       "593   -48.005324  -26.488251  \n",
       "677   -10.740440  -64.210182  \n",
       "41     56.270284   24.790283  \n",
       "2421         NaN         NaN  \n",
       "1392  -30.149319  -12.868166  \n",
       "2784         NaN         NaN  \n",
       "243    35.614280    2.562854  \n",
       "...          ...         ...  \n",
       "3385         NaN         NaN  \n",
       "459   -18.864502  -60.342689  \n",
       "1184    1.838732    2.326320  \n",
       "2324  -40.096432  -11.759425  \n",
       "955    -4.728832  -16.462145  \n",
       "1215    2.838267  -17.907923  \n",
       "2433         NaN         NaN  \n",
       "2853         NaN         NaN  \n",
       "1515  209.840777   90.046588  \n",
       "2391         NaN         NaN  \n",
       "769   -20.062777  -13.209668  \n",
       "3380         NaN         NaN  \n",
       "1685   24.272326    5.603732  \n",
       "130   -10.305468   10.291843  \n",
       "2919         NaN         NaN  \n",
       "3171         NaN         NaN  \n",
       "3444         NaN         NaN  \n",
       "2135   52.897284   66.315937  \n",
       "1482    0.012359  -20.256296  \n",
       "330   -13.060825   -9.118840  \n",
       "1238  -36.420552  -23.405306  \n",
       "466   -36.579050   54.562207  \n",
       "2169   -9.033074  -18.234175  \n",
       "1638  -12.311393  -37.165452  \n",
       "3092         NaN         NaN  \n",
       "1095   -3.579006  -33.057568  \n",
       "1130  -67.336560   78.885060  \n",
       "1294    8.997108   83.819632  \n",
       "860   -10.310306  -21.724621  \n",
       "3174         NaN         NaN  \n",
       "\n",
       "[2337 rows x 231 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA(n_components=8,random_state=2,svd_solver='full')\n",
    "pcaX_train=pd.DataFrame(pca.fit_transform(X_train))\n",
    "x2=X_train.join(pcaX_train)\n",
    "#x2.insert(loc=0,value=pd.DataFrame(pcaX_train),column=pcaX_train.columns)\n",
    "print (X_train.shape)\n",
    "print (pcaX_train.shape)\n",
    "print (x2.shape)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca=PCA(n_components=8,random_state=2,svd_solver='full')\n",
    "pcaX_train=pca.fit_transform(X_train)\n",
    "pcaX_train, y_res = ros.fit_sample(pcaX_train,y_train)\n",
    "pcaX_test=pca.transform(X_test)\n",
    "show_score(rf,pcaX_train,pcaX_test, y_res, y_test,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подбор параметров модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор по сетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 168 candidates, totalling 840 fits\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=10, score=0.386207, total=   0.0s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=10 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, max_features=auto, n_estimators=10, score=0.378325, total=   0.0s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=10, score=0.387192, total=   0.0s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=10 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=1, max_features=auto, n_estimators=10, score=0.394089, total=   0.0s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=10, score=0.375369, total=   0.0s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=30, score=0.397044, total=   0.1s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=30, score=0.398030, total=   0.1s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=30, score=0.400000, total=   0.1s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=30, score=0.426601, total=   0.1s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=30, score=0.394089, total=   0.1s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=50, score=0.385222, total=   0.3s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=50, score=0.382266, total=   0.3s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=50, score=0.400000, total=   0.3s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=50, score=0.405911, total=   0.3s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=50, score=0.406897, total=   0.3s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=100, score=0.400000, total=   0.6s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=100, score=0.391133, total=   0.6s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=100, score=0.398030, total=   0.6s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=100, score=0.405911, total=   0.8s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=100, score=0.422660, total=   0.9s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=200, score=0.405911, total=   2.4s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=200, score=0.390148, total=   1.5s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=200, score=0.401970, total=   1.6s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=200, score=0.408867, total=   1.8s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=200, score=0.414778, total=   1.7s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=300, score=0.401970, total=   2.4s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=300, score=0.395074, total=   2.2s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=300, score=0.409852, total=   2.1s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=300, score=0.402956, total=   2.1s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=300, score=0.417734, total=   2.3s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=500, score=0.399015, total=   4.0s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=500, score=0.398030, total=   3.7s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=500, score=0.402956, total=   3.5s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=500, score=0.404926, total=   3.5s\n",
      "[CV] max_depth=1, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=auto, n_estimators=500, score=0.419704, total=   3.7s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=10, score=0.386207, total=   0.0s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=10, score=0.378325, total=   0.0s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=10, score=0.387192, total=   0.0s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=10, score=0.394089, total=   0.0s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=10, score=0.375369, total=   0.0s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=30, score=0.397044, total=   0.1s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=30, score=0.398030, total=   0.2s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=30, score=0.400000, total=   0.2s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=30, score=0.426601, total=   0.1s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=30, score=0.394089, total=   0.1s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=50, score=0.385222, total=   0.3s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=50, score=0.382266, total=   0.4s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=50, score=0.400000, total=   0.5s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=50, score=0.405911, total=   0.4s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=50, score=0.406897, total=   0.3s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=100, score=0.400000, total=   0.7s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=100, score=0.391133, total=   0.7s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=100, score=0.398030, total=   0.7s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=100, score=0.405911, total=   0.7s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=100, score=0.422660, total=   0.7s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=200, score=0.405911, total=   1.4s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=200, score=0.390148, total=   1.7s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=200, score=0.401970, total=   1.7s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=200, score=0.408867, total=   1.6s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=200, score=0.414778, total=   1.5s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=300, score=0.401970, total=   2.3s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=300, score=0.395074, total=   2.2s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=300, score=0.409852, total=   2.3s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=300, score=0.402956, total=   2.3s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=300, score=0.417734, total=   2.4s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=500, score=0.399015, total=   3.8s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=500, score=0.398030, total=   4.1s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=500, score=0.402956, total=   3.6s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=500, score=0.404926, total=   3.9s\n",
      "[CV] max_depth=1, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=sqrt, n_estimators=500, score=0.419704, total=   3.8s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=10, score=0.402956, total=   0.0s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=10, score=0.376355, total=   0.0s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=10, score=0.397044, total=   0.0s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=10, score=0.392118, total=   0.0s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=10, score=0.391133, total=   0.0s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=30, score=0.379310, total=   0.1s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=30, score=0.392118, total=   0.1s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=30, score=0.391133, total=   0.2s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=30, score=0.417734, total=   0.2s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=30, score=0.399015, total=   0.1s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=50, score=0.381281, total=   0.3s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=50, score=0.379310, total=   0.3s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=50, score=0.392118, total=   0.3s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=50, score=0.402956, total=   0.3s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=50, score=0.403941, total=   0.3s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=100, score=0.380296, total=   0.6s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=100, score=0.380296, total=   0.6s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=100, score=0.394089, total=   0.6s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=100, score=0.409852, total=   0.7s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=100, score=0.399015, total=   0.7s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=200, score=0.380296, total=   1.5s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=200, score=0.380296, total=   1.5s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=200, score=0.395074, total=   1.4s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=200, score=0.412808, total=   1.7s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=200, score=0.399015, total=   1.5s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=300, score=0.385222, total=   2.2s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=300, score=0.383251, total=   2.2s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=300, score=0.398030, total=   2.4s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=300, score=0.408867, total=   2.2s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=300, score=0.406897, total=   2.2s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=500, score=0.380296, total=   3.8s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=500, score=0.380296, total=   4.0s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=500, score=0.392118, total=   3.9s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=500, score=0.408867, total=   4.4s\n",
      "[CV] max_depth=1, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=1, max_features=log2, n_estimators=500, score=0.406897, total=   3.8s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=10, score=0.466995, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=10, score=0.484729, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=10, score=0.448276, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=10, score=0.455172, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=10, score=0.463054, total=   0.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=30, score=0.470936, total=   0.2s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=30, score=0.463054, total=   0.2s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=30, score=0.458128, total=   0.2s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=30, score=0.476847, total=   0.2s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=30, score=0.464039, total=   0.2s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=50, score=0.474877, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=50, score=0.451232, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=50, score=0.471921, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=50, score=0.494581, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=50, score=0.484729, total=   0.3s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=100, score=0.466010, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=100, score=0.451232, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=100, score=0.464039, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=100, score=0.500493, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=100, score=0.497537, total=   0.7s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=200, score=0.479803, total=   1.5s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=200, score=0.458128, total=   1.5s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=200, score=0.477833, total=   1.6s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=200, score=0.508374, total=   1.5s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=200, score=0.495567, total=   2.1s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=300, score=0.480788, total=   2.3s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=300, score=0.469951, total=   2.5s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=300, score=0.479803, total=   2.4s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=300, score=0.502463, total=   2.3s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=300, score=0.497537, total=   2.4s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=500, score=0.473892, total=   3.9s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=500, score=0.469951, total=   4.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=500, score=0.480788, total=   4.0s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=500, score=0.492611, total=   4.1s\n",
      "[CV] max_depth=3, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=auto, n_estimators=500, score=0.488670, total=   4.0s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=10, score=0.466995, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=10, score=0.484729, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=10, score=0.448276, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=10, score=0.455172, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=10, score=0.463054, total=   0.0s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=30, score=0.470936, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=30, score=0.463054, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=30, score=0.458128, total=   0.1s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=30, score=0.476847, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=30, score=0.464039, total=   0.2s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=50, score=0.474877, total=   0.3s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=50, score=0.451232, total=   0.3s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=50, score=0.471921, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=50, score=0.494581, total=   0.3s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=50, score=0.484729, total=   0.4s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=100, score=0.466010, total=   0.8s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=100, score=0.451232, total=   0.7s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=100, score=0.464039, total=   0.7s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=100, score=0.500493, total=   0.7s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=100, score=0.497537, total=   0.7s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=200, score=0.479803, total=   1.6s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=200, score=0.458128, total=   1.7s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=200, score=0.477833, total=   1.6s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=200, score=0.508374, total=   2.1s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=200, score=0.495567, total=   1.7s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=300, score=0.480788, total=   2.4s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=300, score=0.469951, total=   2.4s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=300, score=0.479803, total=   2.4s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=300, score=0.502463, total=   2.4s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=300, score=0.497537, total=   2.3s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=500, score=0.473892, total=   3.9s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=500, score=0.469951, total=   3.9s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=500, score=0.480788, total=   3.9s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=500, score=0.492611, total=   3.9s\n",
      "[CV] max_depth=3, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=sqrt, n_estimators=500, score=0.488670, total=   3.9s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=10, score=0.489655, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=10, score=0.496552, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=10, score=0.471921, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=10, score=0.455172, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=10, score=0.473892, total=   0.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=30, score=0.468966, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=30, score=0.462069, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=30, score=0.470936, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=30, score=0.497537, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=30, score=0.467980, total=   0.2s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=50, score=0.470936, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=50, score=0.460099, total=   0.3s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=50, score=0.475862, total=   0.3s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=50, score=0.487685, total=   0.3s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=50, score=0.478818, total=   0.4s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=100, score=0.466010, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=100, score=0.443350, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=100, score=0.474877, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=100, score=0.492611, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=100, score=0.484729, total=   0.8s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=200, score=0.466010, total=   1.7s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=200, score=0.466995, total=   1.7s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=200, score=0.476847, total=   1.6s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=200, score=0.488670, total=   1.6s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=200, score=0.482759, total=   1.6s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=300, score=0.469951, total=   2.6s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=300, score=0.457143, total=   2.7s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=300, score=0.476847, total=   3.0s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=300, score=0.492611, total=   2.6s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=300, score=0.479803, total=   2.7s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=500, score=0.464039, total=   4.3s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=500, score=0.447291, total=   4.3s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=500, score=0.471921, total=   4.3s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=500, score=0.484729, total=   4.2s\n",
      "[CV] max_depth=3, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=3, max_features=log2, n_estimators=500, score=0.475862, total=   4.6s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=10, score=0.563547, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=10, score=0.587192, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=10, score=0.579310, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=10, score=0.562562, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=10, score=0.590148, total=   0.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=30, score=0.577340, total=   0.2s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=30, score=0.586207, total=   0.2s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=30, score=0.606897, total=   0.2s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=30, score=0.598030, total=   0.3s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=30, score=0.599015, total=   0.3s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=50, score=0.581281, total=   0.4s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=50, score=0.582266, total=   0.4s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=50, score=0.603941, total=   0.4s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=50, score=0.594089, total=   0.4s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=50, score=0.604926, total=   0.7s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=100, score=0.581281, total=   1.1s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=100, score=0.594089, total=   1.6s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=100, score=0.616749, total=   1.1s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=100, score=0.593103, total=   1.2s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=100, score=0.607882, total=   1.3s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=200, score=0.589163, total=   2.6s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=200, score=0.582266, total=   2.7s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=200, score=0.617734, total=   2.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=200, score=0.596059, total=   2.2s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=200, score=0.613793, total=   2.6s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=300, score=0.580296, total=   3.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=300, score=0.590148, total=   2.6s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=300, score=0.612808, total=   2.7s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=300, score=0.591133, total=   2.7s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=300, score=0.617734, total=   2.9s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=500, score=0.596059, total=   4.3s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=500, score=0.588177, total=   4.5s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=500, score=0.615764, total=   5.0s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=500, score=0.599015, total=   4.8s\n",
      "[CV] max_depth=5, max_features=auto, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=auto, n_estimators=500, score=0.623645, total=   4.8s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=10, score=0.563547, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=10, score=0.587192, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=10, score=0.579310, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=10, score=0.562562, total=   0.1s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=10, score=0.590148, total=   0.0s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=30, score=0.577340, total=   0.5s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=30, score=0.586207, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=30, score=0.606897, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=30, score=0.598030, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=30, score=0.599015, total=   0.2s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=50, score=0.581281, total=   0.4s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=50, score=0.582266, total=   0.4s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=50, score=0.603941, total=   0.4s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=50, score=0.594089, total=   0.3s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=50, score=0.604926, total=   0.4s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=100, score=0.581281, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=100, score=0.594089, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=100, score=0.616749, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=100, score=0.593103, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=100, score=0.607882, total=   0.8s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=200, score=0.589163, total=   1.7s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=200, score=0.582266, total=   1.7s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=200, score=0.617734, total=   1.6s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=200, score=0.596059, total=   1.7s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=200, score=0.613793, total=   1.7s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=300, score=0.580296, total=   2.6s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=300, score=0.590148, total=   3.0s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=300, score=0.612808, total=   3.1s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=300, score=0.591133, total=   2.8s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=300, score=0.617734, total=   2.8s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=500, score=0.596059, total=   4.5s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=500, score=0.588177, total=   4.8s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=500, score=0.615764, total=   4.6s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=500, score=0.599015, total=   4.6s\n",
      "[CV] max_depth=5, max_features=sqrt, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=sqrt, n_estimators=500, score=0.623645, total=   5.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=10, score=0.589163, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=10, score=0.591133, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=10, score=0.611823, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=10, score=0.587192, total=   0.1s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=10 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=10, score=0.592118, total=   0.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=30, score=0.589163, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=30, score=0.583251, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=30, score=0.613793, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=30, score=0.590148, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=30 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=30, score=0.615764, total=   0.2s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=50, score=0.580296, total=   0.4s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=50, score=0.586207, total=   0.5s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=50, score=0.629557, total=   0.5s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=50, score=0.590148, total=   0.5s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=50 .................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=50, score=0.616749, total=   0.5s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=100, score=0.600985, total=   1.1s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=100, score=0.583251, total=   1.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=100, score=0.624631, total=   0.9s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=100, score=0.595074, total=   0.9s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=100 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=100, score=0.610837, total=   0.9s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=200, score=0.601970, total=   1.9s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=200, score=0.592118, total=   2.1s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=200, score=0.627586, total=   2.1s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=200, score=0.596059, total=   1.9s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=200 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=200, score=0.616749, total=   1.9s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=300, score=0.597044, total=   3.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=300, score=0.592118, total=   3.1s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=300, score=0.626601, total=   3.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=300, score=0.596059, total=   2.9s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=300 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=300, score=0.609852, total=   3.4s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=500, score=0.602956, total=   5.1s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=500, score=0.592118, total=   5.0s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=500, score=0.622660, total=   5.1s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=500, score=0.594089, total=   5.5s\n",
      "[CV] max_depth=5, max_features=log2, n_estimators=500 ................\n",
      "[CV]  max_depth=5, max_features=log2, n_estimators=500, score=0.611823, total=   5.4s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=10, score=0.770443, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=10, score=0.798030, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=10, score=0.800000, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=10, score=0.781281, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=10, score=0.855172, total=   0.0s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=30, score=0.769458, total=   0.3s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=30, score=0.803941, total=   0.3s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=30, score=0.827586, total=   0.3s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=30, score=0.811823, total=   0.4s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=30, score=0.845320, total=   0.3s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=50, score=0.769458, total=   0.5s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=50, score=0.799015, total=   0.5s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=50, score=0.833498, total=   0.5s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=50, score=0.806897, total=   0.5s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=50, score=0.833498, total=   0.5s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=100, score=0.780296, total=   1.0s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=100, score=0.809852, total=   1.1s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=100, score=0.839409, total=   1.0s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=100, score=0.807882, total=   1.2s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=100, score=0.846305, total=   1.0s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=200, score=0.792118, total=   2.1s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=200, score=0.814778, total=   2.2s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=200, score=0.837438, total=   2.2s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=200, score=0.814778, total=   2.2s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=200, score=0.850246, total=   2.3s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=300, score=0.791133, total=   3.6s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=300, score=0.814778, total=   3.5s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=300, score=0.837438, total=   3.8s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=300, score=0.806897, total=   3.4s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=300, score=0.855172, total=   3.6s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=500, score=0.793103, total=   5.3s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=500, score=0.813793, total=   5.3s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=500, score=0.837438, total=   5.9s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=500, score=0.813793, total=   5.8s\n",
      "[CV] max_depth=10, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=auto, n_estimators=500, score=0.857143, total=   5.5s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=10, score=0.770443, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=10, score=0.798030, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=10, score=0.800000, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=10, score=0.781281, total=   0.0s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=10, score=0.855172, total=   0.1s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=30, score=0.769458, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=30, score=0.803941, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=30, score=0.827586, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=30, score=0.811823, total=   0.3s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=30, score=0.845320, total=   0.4s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=50, score=0.769458, total=   0.7s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=50, score=0.799015, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=50, score=0.833498, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=50, score=0.806897, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=50, score=0.833498, total=   0.5s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=100, score=0.780296, total=   1.0s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=100, score=0.809852, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=100, score=0.839409, total=   1.2s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=100, score=0.807882, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=100, score=0.846305, total=   1.1s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=200, score=0.792118, total=   2.3s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=200, score=0.814778, total=   2.3s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=200, score=0.837438, total=   2.4s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=200, score=0.814778, total=   3.2s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=200, score=0.850246, total=   3.5s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=300, score=0.791133, total=   4.6s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=300, score=0.814778, total=   3.9s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=300, score=0.837438, total=   3.6s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=300, score=0.806897, total=   3.7s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=300, score=0.855172, total=   3.5s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=500, score=0.793103, total=   5.6s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=500, score=0.813793, total=   5.9s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=500, score=0.837438, total=   5.3s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=500, score=0.813793, total=   5.6s\n",
      "[CV] max_depth=10, max_features=sqrt, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=sqrt, n_estimators=500, score=0.857143, total=   5.5s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=10, score=0.768473, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=10, score=0.788177, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=10, score=0.804926, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=10, score=0.806897, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=10 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=10, score=0.848276, total=   0.1s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=30, score=0.788177, total=   0.3s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=30, score=0.802956, total=   0.3s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=30, score=0.820690, total=   0.3s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=30, score=0.810837, total=   0.3s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=30 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=30, score=0.835468, total=   0.3s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=50, score=0.792118, total=   0.6s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=50, score=0.799015, total=   0.6s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=50, score=0.832512, total=   0.6s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=50, score=0.814778, total=   0.6s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=50 ................\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=50, score=0.831527, total=   0.6s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=100, score=0.799015, total=   1.3s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=100, score=0.811823, total=   1.4s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=100, score=0.829557, total=   1.3s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=100, score=0.804926, total=   1.2s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=100 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=100, score=0.840394, total=   1.2s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=200, score=0.797044, total=   2.5s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=200, score=0.805911, total=   2.5s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=200, score=0.839409, total=   2.4s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=200, score=0.805911, total=   2.5s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=200 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=200, score=0.836453, total=   2.5s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=300, score=0.798030, total=   4.5s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=300, score=0.808867, total=   4.0s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=300, score=0.834483, total=   4.0s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=300, score=0.809852, total=   4.0s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=300 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=300, score=0.836453, total=   3.8s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=500, score=0.800985, total=   6.1s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=500, score=0.807882, total=   6.3s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=500, score=0.842365, total=   6.9s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=500, score=0.815764, total=   6.7s\n",
      "[CV] max_depth=10, max_features=log2, n_estimators=500 ...............\n",
      "[CV]  max_depth=10, max_features=log2, n_estimators=500, score=0.836453, total=   6.5s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=10, score=0.810837, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=10, score=0.838424, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=10, score=0.859113, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=10, score=0.843350, total=   0.0s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=10, score=0.899507, total=   0.1s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=30, score=0.822660, total=   0.3s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=30, score=0.860099, total=   0.4s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=30, score=0.880788, total=   0.3s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=30, score=0.864039, total=   0.4s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=30, score=0.915271, total=   0.3s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=50, score=0.825616, total=   0.6s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=50, score=0.867980, total=   0.6s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=50, score=0.882759, total=   0.6s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=50, score=0.857143, total=   0.6s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=50, score=0.915271, total=   0.6s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=100, score=0.835468, total=   1.4s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=100, score=0.866995, total=   1.4s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=100, score=0.884729, total=   1.3s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=100, score=0.861084, total=   1.5s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=100, score=0.923153, total=   1.4s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=200, score=0.839409, total=   2.8s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=200, score=0.866010, total=   2.7s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=200, score=0.880788, total=   3.0s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=200, score=0.864039, total=   2.6s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=200, score=0.927094, total=   2.8s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=300, score=0.842365, total=   5.1s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=300, score=0.870936, total=   4.2s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=300, score=0.880788, total=   4.2s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=300, score=0.863054, total=   4.2s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=300, score=0.922167, total=   4.4s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=500, score=0.841379, total=   6.7s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=500, score=0.872906, total=   6.7s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=500, score=0.881773, total=   6.7s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=500, score=0.866995, total=   7.2s\n",
      "[CV] max_depth=20, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=auto, n_estimators=500, score=0.921182, total=   6.8s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=10, score=0.810837, total=   0.0s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=10, score=0.838424, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=10, score=0.859113, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=10, score=0.843350, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=10, score=0.899507, total=   0.1s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=30, score=0.822660, total=   0.4s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=30, score=0.860099, total=   0.4s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=30, score=0.880788, total=   0.3s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=30, score=0.864039, total=   0.4s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=30, score=0.915271, total=   0.3s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=50, score=0.825616, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=50, score=0.867980, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=50, score=0.882759, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=50, score=0.857143, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=50, score=0.915271, total=   0.6s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=100, score=0.835468, total=   1.3s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=100, score=0.866995, total=   1.3s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=100, score=0.884729, total=   1.3s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=100, score=0.861084, total=   1.5s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=100, score=0.923153, total=   1.4s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=200, score=0.839409, total=   2.6s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=200, score=0.866010, total=   2.9s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=200, score=0.880788, total=   2.9s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=200, score=0.864039, total=   2.8s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=200, score=0.927094, total=   2.7s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=300, score=0.842365, total=   4.6s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=300, score=0.870936, total=   4.0s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=300, score=0.880788, total=   5.1s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=300, score=0.863054, total=   4.0s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=300, score=0.922167, total=   4.0s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=500, score=0.841379, total=   8.3s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=500, score=0.872906, total=   7.5s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=500, score=0.881773, total=   6.6s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=500, score=0.866995, total=   7.2s\n",
      "[CV] max_depth=20, max_features=sqrt, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=sqrt, n_estimators=500, score=0.921182, total=   6.9s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=10, score=0.821675, total=   0.0s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=10, score=0.842365, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=10, score=0.865025, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=10, score=0.842365, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=10 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=10, score=0.904433, total=   0.1s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=30, score=0.825616, total=   0.4s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=30, score=0.859113, total=   0.4s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=30, score=0.876847, total=   0.4s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=30, score=0.858128, total=   0.4s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=30 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=30, score=0.909360, total=   0.4s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=50, score=0.836453, total=   0.7s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=50, score=0.857143, total=   0.7s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=50, score=0.880788, total=   0.7s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=50, score=0.860099, total=   0.7s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=50 ................\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=50, score=0.911330, total=   0.7s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=100, score=0.836453, total=   1.4s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=100, score=0.868966, total=   1.4s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=100, score=0.872906, total=   1.5s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=100, score=0.866995, total=   1.4s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=100 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=100, score=0.918227, total=   1.4s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=200, score=0.837438, total=   3.0s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=200, score=0.864039, total=   3.0s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=200, score=0.881773, total=   3.4s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=200, score=0.868966, total=   4.4s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=200 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=200, score=0.922167, total=   3.9s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=300, score=0.836453, total=   5.6s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=300, score=0.867980, total=   4.4s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=300, score=0.879803, total=   4.5s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=300, score=0.870936, total=   4.6s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=300 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=300, score=0.920197, total=   4.7s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=500, score=0.838424, total=   7.5s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=500, score=0.866010, total=   7.5s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=500, score=0.881773, total=   7.6s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=500, score=0.866995, total=   7.8s\n",
      "[CV] max_depth=20, max_features=log2, n_estimators=500 ...............\n",
      "[CV]  max_depth=20, max_features=log2, n_estimators=500, score=0.921182, total=   7.7s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=10, score=0.815764, total=   0.0s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=10, score=0.848276, total=   0.1s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=10, score=0.849261, total=   0.0s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=10, score=0.846305, total=   0.0s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=10 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=10, score=0.899507, total=   0.0s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=30, score=0.827586, total=   0.3s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=30, score=0.853202, total=   0.3s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=30, score=0.876847, total=   0.3s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=30, score=0.865025, total=   0.3s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=30 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=30, score=0.912315, total=   0.3s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=0.833498, total=   0.6s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=0.860099, total=   0.6s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=0.870936, total=   0.6s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=0.866995, total=   0.6s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=50, score=0.919212, total=   0.6s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=100, score=0.832512, total=   1.3s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=100, score=0.858128, total=   1.2s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=100, score=0.874877, total=   1.3s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=100, score=0.867980, total=   1.3s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=100 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=100, score=0.917241, total=   1.2s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=200, score=0.840394, total=   2.7s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=200, score=0.866010, total=   2.7s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=200, score=0.879803, total=   2.6s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=200, score=0.866010, total=   3.1s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=200 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=200, score=0.923153, total=   2.6s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=300, score=0.840394, total=   4.0s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=300, score=0.872906, total=   5.1s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=300, score=0.879803, total=   5.2s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=300, score=0.870936, total=   4.4s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=300 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=300, score=0.921182, total=   4.1s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=500, score=0.840394, total=   8.1s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=500, score=0.868966, total=   7.3s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=500, score=0.881773, total=   7.4s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=500, score=0.872906, total=   8.1s\n",
      "[CV] max_depth=50, max_features=auto, n_estimators=500 ...............\n",
      "[CV]  max_depth=50, max_features=auto, n_estimators=500, score=0.922167, total=   9.4s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=10, score=0.815764, total=   0.1s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=10, score=0.848276, total=   0.1s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=10, score=0.849261, total=   0.0s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=10, score=0.846305, total=   0.0s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=10 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=10, score=0.899507, total=   0.1s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=30, score=0.827586, total=   0.3s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=30, score=0.853202, total=   0.3s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=30, score=0.876847, total=   0.3s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=30, score=0.865025, total=   0.3s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=30 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=30, score=0.912315, total=   0.3s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=50, score=0.833498, total=   0.6s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=50, score=0.860099, total=   0.6s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=50, score=0.870936, total=   0.6s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=50, score=0.866995, total=   0.6s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=50 ................\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=50, score=0.919212, total=   0.6s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=100, score=0.832512, total=   1.4s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=100, score=0.858128, total=   1.2s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=100, score=0.874877, total=   1.3s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=100, score=0.867980, total=   1.3s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=100 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=100, score=0.917241, total=   1.3s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=200, score=0.840394, total=   2.8s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=200, score=0.866010, total=   2.9s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=200, score=0.879803, total=   2.7s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=200, score=0.866010, total=   2.7s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=200 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=200, score=0.923153, total=   3.1s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=300, score=0.840394, total=   5.2s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=300, score=0.872906, total=   4.0s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=300, score=0.879803, total=   6.0s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=300, score=0.870936, total=   6.1s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=300 ...............\n",
      "[CV]  max_depth=50, max_features=sqrt, n_estimators=300, score=0.921182, total=   5.9s\n",
      "[CV] max_depth=50, max_features=sqrt, n_estimators=500 ...............\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-d1de28fa4869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mCV_rfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrf_param_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mCV_rfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_res\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mCV_rfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mCV_rfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0mtrain_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \"\"\"\n\u001b[0;32m--> 534\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    581\u001b[0m             delayed(parallel_helper)(e, 'predict_proba', X,\n\u001b[1;32m    582\u001b[0m                                       check_input=False)\n\u001b[0;32m--> 583\u001b[0;31m             for e in self.estimators_)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36mparallel_helper\u001b[0;34m(obj, methodname, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mparallel_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethodname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[1;34m\"\"\"Helper to workaround Python 2 limitations of pickling instance methods\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethodname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Evtisov_SS\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mnormalizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m             \u001b[0mnormalizer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnormalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m             \u001b[0mproba\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_param_grid = { \n",
    "    'n_estimators': [10,30,50,100,200,300,500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [1,3,5,10,20,50,70,100]\n",
    "}\n",
    "clf = RandomForestClassifier(random_state=1)\n",
    "CV_rfc = GridSearchCV(estimator=clf, param_grid=rf_param_grid, cv= 5,verbose=5)\n",
    "CV_rfc.fit(X_res[best_cols],y_res)\n",
    "print (CV_rfc.best_params_)\n",
    "print (CV_rfc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подбор перебором по отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  max_features  max_depth  score\n",
       "0           1.0           2.0        3.0    4.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=pd.DataFrame(columns=['n_estimators','max_features','max_depth','score'])\n",
    "row=pd.Series(data=[1,2,3,4],index=['n_estimators','max_features','max_depth','score'])\n",
    "res.loc[len(res)]=row\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 840 10 auto 1 0.284722222222\n",
      "2 / 840 10 auto 1 0.335069444444\n",
      "3 / 840 10 auto 1 0.378472222222\n",
      "4 / 840 10 auto 1 0.344618055556\n",
      "5 / 840 10 auto 1 0.284722222222\n",
      "6 / 840 10 auto 3 0.373263888889\n",
      "7 / 840 10 auto 3 0.328993055556\n",
      "8 / 840 10 auto 3 0.363715277778\n",
      "9 / 840 10 auto 3 0.338541666667\n",
      "10 / 840 10 auto 3 0.357638888889\n",
      "11 / 840 10 auto 5 0.421875\n",
      "12 / 840 10 auto 5 0.403645833333\n",
      "13 / 840 10 auto 5 0.414930555556\n",
      "14 / 840 10 auto 5 0.420138888889\n",
      "15 / 840 10 auto 5 0.381076388889\n",
      "16 / 840 10 auto 10 0.527777777778\n",
      "17 / 840 10 auto 10 0.536458333333\n",
      "18 / 840 10 auto 10 0.525173611111\n",
      "19 / 840 10 auto 10 0.555555555556\n",
      "20 / 840 10 auto 10 0.556423611111\n",
      "21 / 840 10 auto 20 0.581597222222\n",
      "22 / 840 10 auto 20 0.59375\n",
      "23 / 840 10 auto 20 0.572916666667\n",
      "24 / 840 10 auto 20 0.581597222222\n",
      "25 / 840 10 auto 20 0.566840277778\n",
      "26 / 840 10 auto 50 0.578125\n",
      "27 / 840 10 auto 50 0.580729166667\n",
      "28 / 840 10 auto 50 0.584201388889\n",
      "29 / 840 10 auto 50 0.578125\n",
      "30 / 840 10 auto 50 0.586805555556\n",
      "31 / 840 10 auto 70 0.558159722222\n",
      "32 / 840 10 auto 70 0.582465277778\n",
      "33 / 840 10 auto 70 0.566840277778\n",
      "34 / 840 10 auto 70 0.565104166667\n",
      "35 / 840 10 auto 70 0.560763888889\n",
      "36 / 840 10 auto 100 0.584201388889\n",
      "37 / 840 10 auto 100 0.580729166667\n",
      "38 / 840 10 auto 100 0.575520833333\n",
      "39 / 840 10 auto 100 0.5703125\n",
      "40 / 840 10 auto 100 0.578125\n",
      "41 / 840 10 sqrt 1 0.3359375\n",
      "42 / 840 10 sqrt 1 0.298611111111\n",
      "43 / 840 10 sqrt 1 0.347222222222\n",
      "44 / 840 10 sqrt 1 0.299479166667\n",
      "45 / 840 10 sqrt 1 0.280381944444\n",
      "46 / 840 10 sqrt 3 0.381944444444\n",
      "47 / 840 10 sqrt 3 0.3359375\n",
      "48 / 840 10 sqrt 3 0.379340277778\n",
      "49 / 840 10 sqrt 3 0.352430555556\n",
      "50 / 840 10 sqrt 3 0.363715277778\n",
      "51 / 840 10 sqrt 5 0.395833333333\n",
      "52 / 840 10 sqrt 5 0.418402777778\n",
      "53 / 840 10 sqrt 5 0.415798611111\n",
      "54 / 840 10 sqrt 5 0.408854166667\n",
      "55 / 840 10 sqrt 5 0.421875\n",
      "56 / 840 10 sqrt 10 0.525173611111\n",
      "57 / 840 10 sqrt 10 0.528645833333\n",
      "58 / 840 10 sqrt 10 0.540798611111\n",
      "59 / 840 10 sqrt 10 0.508680555556\n",
      "60 / 840 10 sqrt 10 0.5390625\n",
      "61 / 840 10 sqrt 20 0.595486111111\n",
      "62 / 840 10 sqrt 20 0.567708333333\n",
      "63 / 840 10 sqrt 20 0.583333333333\n",
      "64 / 840 10 sqrt 20 0.576388888889\n",
      "65 / 840 10 sqrt 20 0.577256944444\n",
      "66 / 840 10 sqrt 50 0.597222222222\n",
      "67 / 840 10 sqrt 50 0.5859375\n",
      "68 / 840 10 sqrt 50 0.572048611111\n",
      "69 / 840 10 sqrt 50 0.5703125\n",
      "70 / 840 10 sqrt 50 0.6015625\n",
      "71 / 840 10 sqrt 70 0.561631944444\n",
      "72 / 840 10 sqrt 70 0.581597222222\n",
      "73 / 840 10 sqrt 70 0.581597222222\n",
      "74 / 840 10 sqrt 70 0.585069444444\n",
      "75 / 840 10 sqrt 70 0.572048611111\n",
      "76 / 840 10 sqrt 100 0.572048611111\n",
      "77 / 840 10 sqrt 100 0.591145833333\n",
      "78 / 840 10 sqrt 100 0.573784722222\n",
      "79 / 840 10 sqrt 100 0.590277777778\n",
      "80 / 840 10 sqrt 100 0.586805555556\n",
      "81 / 840 10 log2 1 0.299479166667\n",
      "82 / 840 10 log2 1 0.299479166667\n",
      "83 / 840 10 log2 1 0.267361111111\n",
      "84 / 840 10 log2 1 0.3203125\n",
      "85 / 840 10 log2 1 0.376736111111\n",
      "86 / 840 10 log2 3 0.387152777778\n",
      "87 / 840 10 log2 3 0.408854166667\n",
      "88 / 840 10 log2 3 0.373263888889\n",
      "89 / 840 10 log2 3 0.388888888889\n",
      "90 / 840 10 log2 3 0.405381944444\n",
      "91 / 840 10 log2 5 0.425347222222\n",
      "92 / 840 10 log2 5 0.40625\n",
      "93 / 840 10 log2 5 0.426215277778\n",
      "94 / 840 10 log2 5 0.460069444444\n",
      "95 / 840 10 log2 5 0.425347222222\n",
      "96 / 840 10 log2 10 0.538194444444\n",
      "97 / 840 10 log2 10 0.534722222222\n",
      "98 / 840 10 log2 10 0.526041666667\n",
      "99 / 840 10 log2 10 0.532986111111\n",
      "100 / 840 10 log2 10 0.508680555556\n",
      "101 / 840 10 log2 20 0.576388888889\n",
      "102 / 840 10 log2 20 0.587673611111\n",
      "103 / 840 10 log2 20 0.581597222222\n",
      "104 / 840 10 log2 20 0.573784722222\n",
      "105 / 840 10 log2 20 0.579861111111\n",
      "106 / 840 10 log2 50 0.565972222222\n",
      "107 / 840 10 log2 50 0.590277777778\n",
      "108 / 840 10 log2 50 0.578125\n",
      "109 / 840 10 log2 50 0.563368055556\n",
      "110 / 840 10 log2 50 0.571180555556\n",
      "111 / 840 10 log2 70 0.585069444444\n",
      "112 / 840 10 log2 70 0.582465277778\n",
      "113 / 840 10 log2 70 0.572048611111\n",
      "114 / 840 10 log2 70 0.558159722222\n",
      "115 / 840 10 log2 70 0.582465277778\n",
      "116 / 840 10 log2 100 0.583333333333\n",
      "117 / 840 10 log2 100 0.574652777778\n",
      "118 / 840 10 log2 100 0.569444444444\n",
      "119 / 840 10 log2 100 0.590277777778\n",
      "120 / 840 10 log2 100 0.578125\n",
      "121 / 840 30 auto 1 0.299479166667\n",
      "122 / 840 30 auto 1 0.298611111111\n",
      "123 / 840 30 auto 1 0.294270833333\n",
      "124 / 840 30 auto 1 0.311631944444\n",
      "125 / 840 30 auto 1 0.291666666667\n",
      "126 / 840 30 auto 3 0.364583333333\n",
      "127 / 840 30 auto 3 0.394965277778\n",
      "128 / 840 30 auto 3 0.394097222222\n",
      "129 / 840 30 auto 3 0.366319444444\n",
      "130 / 840 30 auto 3 0.360243055556\n",
      "131 / 840 30 auto 5 0.427951388889\n",
      "132 / 840 30 auto 5 0.403645833333\n",
      "133 / 840 30 auto 5 0.443576388889\n",
      "134 / 840 30 auto 5 0.408854166667\n",
      "135 / 840 30 auto 5 0.425347222222\n",
      "136 / 840 30 auto 10 0.553819444444\n",
      "137 / 840 30 auto 10 0.549479166667\n",
      "138 / 840 30 auto 10 0.544270833333\n",
      "139 / 840 30 auto 10 0.546006944444\n",
      "140 / 840 30 auto 10 0.559027777778\n",
      "141 / 840 30 auto 20 0.618923611111\n",
      "142 / 840 30 auto 20 0.597222222222\n",
      "143 / 840 30 auto 20 0.608506944444\n",
      "144 / 840 30 auto 20 0.595486111111\n",
      "145 / 840 30 auto 20 0.598958333333\n",
      "146 / 840 30 auto 50 0.604166666667\n",
      "147 / 840 30 auto 50 0.613715277778\n",
      "148 / 840 30 auto 50 0.614583333333\n",
      "149 / 840 30 auto 50 0.609375\n",
      "150 / 840 30 auto 50 0.606770833333\n",
      "151 / 840 30 auto 70 0.607638888889\n",
      "152 / 840 30 auto 70 0.600694444444\n",
      "153 / 840 30 auto 70 0.602430555556\n",
      "154 / 840 30 auto 70 0.591145833333\n",
      "155 / 840 30 auto 70 0.603298611111\n",
      "156 / 840 30 auto 100 0.607638888889\n",
      "157 / 840 30 auto 100 0.609375\n",
      "158 / 840 30 auto 100 0.625868055556\n",
      "159 / 840 30 auto 100 0.604166666667\n",
      "160 / 840 30 auto 100 0.596354166667\n",
      "161 / 840 30 sqrt 1 0.290798611111\n",
      "162 / 840 30 sqrt 1 0.324652777778\n",
      "163 / 840 30 sqrt 1 0.264756944444\n",
      "164 / 840 30 sqrt 1 0.325520833333\n",
      "165 / 840 30 sqrt 1 0.299479166667\n",
      "166 / 840 30 sqrt 3 0.377604166667\n",
      "167 / 840 30 sqrt 3 0.3828125\n",
      "168 / 840 30 sqrt 3 0.369791666667\n",
      "169 / 840 30 sqrt 3 0.363715277778\n",
      "170 / 840 30 sqrt 3 0.357638888889\n",
      "171 / 840 30 sqrt 5 0.434895833333\n",
      "172 / 840 30 sqrt 5 0.421006944444\n",
      "173 / 840 30 sqrt 5 0.428819444444\n",
      "174 / 840 30 sqrt 5 0.435763888889\n",
      "175 / 840 30 sqrt 5 0.422743055556\n",
      "176 / 840 30 sqrt 10 0.552951388889\n",
      "177 / 840 30 sqrt 10 0.546875\n",
      "178 / 840 30 sqrt 10 0.543402777778\n",
      "179 / 840 30 sqrt 10 0.559895833333\n",
      "180 / 840 30 sqrt 10 0.545138888889\n",
      "181 / 840 30 sqrt 20 0.616319444444\n",
      "182 / 840 30 sqrt 20 0.598090277778\n",
      "183 / 840 30 sqrt 20 0.618055555556\n",
      "184 / 840 30 sqrt 20 0.606770833333\n",
      "185 / 840 30 sqrt 20 0.605902777778\n",
      "186 / 840 30 sqrt 50 0.608506944444\n",
      "187 / 840 30 sqrt 50 0.624131944444\n",
      "188 / 840 30 sqrt 50 0.603298611111\n",
      "189 / 840 30 sqrt 50 0.613715277778\n",
      "190 / 840 30 sqrt 50 0.596354166667\n",
      "191 / 840 30 sqrt 70 0.605034722222\n",
      "192 / 840 30 sqrt 70 0.609375\n",
      "193 / 840 30 sqrt 70 0.607638888889\n",
      "194 / 840 30 sqrt 70 0.607638888889\n",
      "195 / 840 30 sqrt 70 0.604166666667\n",
      "196 / 840 30 sqrt 100 0.606770833333\n",
      "197 / 840 30 sqrt 100 0.625868055556\n",
      "198 / 840 30 sqrt 100 0.599826388889\n",
      "199 / 840 30 sqrt 100 0.6171875\n",
      "200 / 840 30 sqrt 100 0.609375\n",
      "201 / 840 30 log2 1 0.282986111111\n",
      "202 / 840 30 log2 1 0.327256944444\n",
      "203 / 840 30 log2 1 0.353298611111\n",
      "204 / 840 30 log2 1 0.263020833333\n",
      "205 / 840 30 log2 1 0.300347222222\n",
      "206 / 840 30 log2 3 0.389756944444\n",
      "207 / 840 30 log2 3 0.376736111111\n",
      "208 / 840 30 log2 3 0.364583333333\n",
      "209 / 840 30 log2 3 0.396701388889\n",
      "210 / 840 30 log2 3 0.363715277778\n",
      "211 / 840 30 log2 5 0.4375\n",
      "212 / 840 30 log2 5 0.426215277778\n",
      "213 / 840 30 log2 5 0.423611111111\n",
      "214 / 840 30 log2 5 0.427083333333\n",
      "215 / 840 30 log2 5 0.455729166667\n",
      "216 / 840 30 log2 10 0.556423611111\n",
      "217 / 840 30 log2 10 0.566840277778\n",
      "218 / 840 30 log2 10 0.559895833333\n",
      "219 / 840 30 log2 10 0.568576388889\n",
      "220 / 840 30 log2 10 0.552951388889\n",
      "221 / 840 30 log2 20 0.599826388889\n",
      "222 / 840 30 log2 20 0.610243055556\n",
      "223 / 840 30 log2 20 0.608506944444\n",
      "224 / 840 30 log2 20 0.606770833333\n",
      "225 / 840 30 log2 20 0.609375\n",
      "226 / 840 30 log2 50 0.597222222222\n",
      "227 / 840 30 log2 50 0.607638888889\n",
      "228 / 840 30 log2 50 0.619791666667\n",
      "229 / 840 30 log2 50 0.584201388889\n",
      "230 / 840 30 log2 50 0.611111111111\n",
      "231 / 840 30 log2 70 0.610243055556\n",
      "232 / 840 30 log2 70 0.608506944444\n",
      "233 / 840 30 log2 70 0.598958333333\n",
      "234 / 840 30 log2 70 0.606770833333\n",
      "235 / 840 30 log2 70 0.589409722222\n",
      "236 / 840 30 log2 100 0.598958333333\n",
      "237 / 840 30 log2 100 0.6015625\n",
      "238 / 840 30 log2 100 0.618923611111\n",
      "239 / 840 30 log2 100 0.592881944444\n",
      "240 / 840 30 log2 100 0.615451388889\n",
      "241 / 840 50 auto 1 0.301215277778\n",
      "242 / 840 50 auto 1 0.319444444444\n",
      "243 / 840 50 auto 1 0.294270833333\n",
      "244 / 840 50 auto 1 0.338541666667\n",
      "245 / 840 50 auto 1 0.276041666667\n",
      "246 / 840 50 auto 3 0.389756944444\n",
      "247 / 840 50 auto 3 0.374131944444\n",
      "248 / 840 50 auto 3 0.386284722222\n",
      "249 / 840 50 auto 3 0.381076388889\n",
      "250 / 840 50 auto 3 0.389756944444\n",
      "251 / 840 50 auto 5 0.425347222222\n",
      "252 / 840 50 auto 5 0.443576388889\n",
      "253 / 840 50 auto 5 0.428819444444\n",
      "254 / 840 50 auto 5 0.430555555556\n",
      "255 / 840 50 auto 5 0.422743055556\n",
      "256 / 840 50 auto 10 0.569444444444\n",
      "257 / 840 50 auto 10 0.556423611111\n",
      "258 / 840 50 auto 10 0.5546875\n",
      "259 / 840 50 auto 10 0.556423611111\n",
      "260 / 840 50 auto 10 0.564236111111\n",
      "261 / 840 50 auto 20 0.618055555556\n",
      "262 / 840 50 auto 20 0.614583333333\n",
      "263 / 840 50 auto 20 0.634548611111\n",
      "264 / 840 50 auto 20 0.611979166667\n",
      "265 / 840 50 auto 20 0.614583333333\n",
      "266 / 840 50 auto 50 0.620659722222\n",
      "267 / 840 50 auto 50 0.618923611111\n",
      "268 / 840 50 auto 50 0.605902777778\n",
      "269 / 840 50 auto 50 0.618923611111\n",
      "270 / 840 50 auto 50 0.608506944444\n",
      "271 / 840 50 auto 70 0.624131944444\n",
      "272 / 840 50 auto 70 0.618923611111\n",
      "273 / 840 50 auto 70 0.613715277778\n",
      "274 / 840 50 auto 70 0.618055555556\n",
      "275 / 840 50 auto 70 0.602430555556\n",
      "276 / 840 50 auto 100 0.614583333333\n",
      "277 / 840 50 auto 100 0.608506944444\n",
      "278 / 840 50 auto 100 0.620659722222\n",
      "279 / 840 50 auto 100 0.606770833333\n",
      "280 / 840 50 auto 100 0.604166666667\n",
      "281 / 840 50 sqrt 1 0.280381944444\n",
      "282 / 840 50 sqrt 1 0.295138888889\n",
      "283 / 840 50 sqrt 1 0.335069444444\n",
      "284 / 840 50 sqrt 1 0.295138888889\n",
      "285 / 840 50 sqrt 1 0.333333333333\n",
      "286 / 840 50 sqrt 3 0.375\n",
      "287 / 840 50 sqrt 3 0.3515625\n",
      "288 / 840 50 sqrt 3 0.365451388889\n",
      "289 / 840 50 sqrt 3 0.364583333333\n",
      "290 / 840 50 sqrt 3 0.361979166667\n",
      "291 / 840 50 sqrt 5 0.411458333333\n",
      "292 / 840 50 sqrt 5 0.419270833333\n",
      "293 / 840 50 sqrt 5 0.440104166667\n",
      "294 / 840 50 sqrt 5 0.428819444444\n",
      "295 / 840 50 sqrt 5 0.434895833333\n",
      "296 / 840 50 sqrt 10 0.561631944444\n",
      "297 / 840 50 sqrt 10 0.565972222222\n",
      "298 / 840 50 sqrt 10 0.561631944444\n",
      "299 / 840 50 sqrt 10 0.5625\n",
      "300 / 840 50 sqrt 10 0.5546875\n",
      "301 / 840 50 sqrt 20 0.606770833333\n",
      "302 / 840 50 sqrt 20 0.618923611111\n",
      "303 / 840 50 sqrt 20 0.622395833333\n",
      "304 / 840 50 sqrt 20 0.625868055556\n",
      "305 / 840 50 sqrt 20 0.618923611111\n",
      "306 / 840 50 sqrt 50 0.622395833333\n",
      "307 / 840 50 sqrt 50 0.620659722222\n",
      "308 / 840 50 sqrt 50 0.6171875\n",
      "309 / 840 50 sqrt 50 0.613715277778\n",
      "310 / 840 50 sqrt 50 0.618923611111\n",
      "311 / 840 50 sqrt 70 0.605902777778\n",
      "312 / 840 50 sqrt 70 0.607638888889\n",
      "313 / 840 50 sqrt 70 0.618055555556\n",
      "314 / 840 50 sqrt 70 0.625\n",
      "315 / 840 50 sqrt 70 0.623263888889\n",
      "316 / 840 50 sqrt 100 0.627604166667\n",
      "317 / 840 50 sqrt 100 0.618055555556\n",
      "318 / 840 50 sqrt 100 0.6171875\n",
      "319 / 840 50 sqrt 100 0.619791666667\n",
      "320 / 840 50 sqrt 100 0.609375\n",
      "321 / 840 50 log2 1 0.299479166667\n",
      "322 / 840 50 log2 1 0.297743055556\n",
      "323 / 840 50 log2 1 0.299479166667\n",
      "324 / 840 50 log2 1 0.296006944444\n",
      "325 / 840 50 log2 1 0.298611111111\n",
      "326 / 840 50 log2 3 0.365451388889\n",
      "327 / 840 50 log2 3 0.390625\n",
      "328 / 840 50 log2 3 0.3828125\n",
      "329 / 840 50 log2 3 0.377604166667\n",
      "330 / 840 50 log2 3 0.379340277778\n",
      "331 / 840 50 log2 5 0.438368055556\n",
      "332 / 840 50 log2 5 0.432291666667\n",
      "333 / 840 50 log2 5 0.439236111111\n",
      "334 / 840 50 log2 5 0.427083333333\n",
      "335 / 840 50 log2 5 0.446180555556\n",
      "336 / 840 50 log2 10 0.567708333333\n",
      "337 / 840 50 log2 10 0.539930555556\n",
      "338 / 840 50 log2 10 0.558159722222\n",
      "339 / 840 50 log2 10 0.552083333333\n",
      "340 / 840 50 log2 10 0.561631944444\n",
      "341 / 840 50 log2 20 0.610243055556\n",
      "342 / 840 50 log2 20 0.615451388889\n",
      "343 / 840 50 log2 20 0.6015625\n",
      "344 / 840 50 log2 20 0.6015625\n",
      "345 / 840 50 log2 20 0.613715277778\n",
      "346 / 840 50 log2 50 0.609375\n",
      "347 / 840 50 log2 50 0.619791666667\n",
      "348 / 840 50 log2 50 0.602430555556\n",
      "349 / 840 50 log2 50 0.607638888889\n",
      "350 / 840 50 log2 50 0.618055555556\n",
      "351 / 840 50 log2 70 0.604166666667\n",
      "352 / 840 50 log2 70 0.603298611111\n",
      "353 / 840 50 log2 70 0.615451388889\n",
      "354 / 840 50 log2 70 0.609375\n",
      "355 / 840 50 log2 70 0.602430555556\n",
      "356 / 840 50 log2 100 0.608506944444\n",
      "357 / 840 50 log2 100 0.631076388889\n",
      "358 / 840 50 log2 100 0.618923611111\n",
      "359 / 840 50 log2 100 0.599826388889\n",
      "360 / 840 50 log2 100 0.613715277778\n",
      "361 / 840 100 auto 1 0.322048611111\n",
      "362 / 840 100 auto 1 0.298611111111\n",
      "363 / 840 100 auto 1 0.314236111111\n",
      "364 / 840 100 auto 1 0.266493055556\n",
      "365 / 840 100 auto 1 0.302083333333\n",
      "366 / 840 100 auto 3 0.381944444444\n",
      "367 / 840 100 auto 3 0.381944444444\n",
      "368 / 840 100 auto 3 0.366319444444\n",
      "369 / 840 100 auto 3 0.397569444444\n",
      "370 / 840 100 auto 3 0.368055555556\n",
      "371 / 840 100 auto 5 0.4296875\n",
      "372 / 840 100 auto 5 0.426215277778\n",
      "373 / 840 100 auto 5 0.424479166667\n",
      "374 / 840 100 auto 5 0.447916666667\n",
      "375 / 840 100 auto 5 0.423611111111\n",
      "376 / 840 100 auto 10 0.567708333333\n",
      "377 / 840 100 auto 10 0.559895833333\n",
      "378 / 840 100 auto 10 0.558159722222\n",
      "379 / 840 100 auto 10 0.555555555556\n",
      "380 / 840 100 auto 10 0.559895833333\n",
      "381 / 840 100 auto 20 0.621527777778\n",
      "382 / 840 100 auto 20 0.623263888889\n",
      "383 / 840 100 auto 20 0.625\n",
      "384 / 840 100 auto 20 0.621527777778\n",
      "385 / 840 100 auto 20 0.618923611111\n",
      "386 / 840 100 auto 50 0.623263888889\n",
      "387 / 840 100 auto 50 0.624131944444\n",
      "388 / 840 100 auto 50 0.625\n",
      "389 / 840 100 auto 50 0.635416666667\n",
      "390 / 840 100 auto 50 0.610243055556\n",
      "391 / 840 100 auto 70 0.620659722222\n",
      "392 / 840 100 auto 70 0.627604166667\n",
      "393 / 840 100 auto 70 0.618923611111\n",
      "394 / 840 100 auto 70 0.620659722222\n",
      "395 / 840 100 auto 70 0.628472222222\n",
      "396 / 840 100 auto 100 0.628472222222\n",
      "397 / 840 100 auto 100 0.619791666667\n",
      "398 / 840 100 auto 100 0.614583333333\n",
      "399 / 840 100 auto 100 0.625868055556\n",
      "400 / 840 100 auto 100 0.628472222222\n",
      "401 / 840 100 sqrt 1 0.336805555556\n",
      "402 / 840 100 sqrt 1 0.302083333333\n",
      "403 / 840 100 sqrt 1 0.324652777778\n",
      "404 / 840 100 sqrt 1 0.299479166667\n",
      "405 / 840 100 sqrt 1 0.314236111111\n",
      "406 / 840 100 sqrt 3 0.375\n",
      "407 / 840 100 sqrt 3 0.378472222222\n",
      "408 / 840 100 sqrt 3 0.387152777778\n",
      "409 / 840 100 sqrt 3 0.366319444444\n",
      "410 / 840 100 sqrt 3 0.3515625\n",
      "411 / 840 100 sqrt 5 0.421875\n",
      "412 / 840 100 sqrt 5 0.426215277778\n",
      "413 / 840 100 sqrt 5 0.452256944444\n",
      "414 / 840 100 sqrt 5 0.4453125\n",
      "415 / 840 100 sqrt 5 0.427083333333\n",
      "416 / 840 100 sqrt 10 0.558159722222\n",
      "417 / 840 100 sqrt 10 0.563368055556\n",
      "418 / 840 100 sqrt 10 0.549479166667\n",
      "419 / 840 100 sqrt 10 0.556423611111\n",
      "420 / 840 100 sqrt 10 0.547743055556\n",
      "421 / 840 100 sqrt 20 0.620659722222\n",
      "422 / 840 100 sqrt 20 0.614583333333\n",
      "423 / 840 100 sqrt 20 0.628472222222\n",
      "424 / 840 100 sqrt 20 0.630208333333\n",
      "425 / 840 100 sqrt 20 0.623263888889\n",
      "426 / 840 100 sqrt 50 0.629340277778\n",
      "427 / 840 100 sqrt 50 0.629340277778\n",
      "428 / 840 100 sqrt 50 0.622395833333\n",
      "429 / 840 100 sqrt 50 0.631076388889\n",
      "430 / 840 100 sqrt 50 0.618923611111\n",
      "431 / 840 100 sqrt 70 0.614583333333\n",
      "432 / 840 100 sqrt 70 0.622395833333\n",
      "433 / 840 100 sqrt 70 0.631944444444\n",
      "434 / 840 100 sqrt 70 0.615451388889\n",
      "435 / 840 100 sqrt 70 0.621527777778\n",
      "436 / 840 100 sqrt 100 0.618923611111\n",
      "437 / 840 100 sqrt 100 0.609375\n",
      "438 / 840 100 sqrt 100 0.623263888889\n",
      "439 / 840 100 sqrt 100 0.625868055556\n",
      "440 / 840 100 sqrt 100 0.625\n",
      "441 / 840 100 log2 1 0.299479166667\n",
      "442 / 840 100 log2 1 0.299479166667\n",
      "443 / 840 100 log2 1 0.299479166667\n",
      "444 / 840 100 log2 1 0.297743055556\n",
      "445 / 840 100 log2 1 0.299479166667\n",
      "446 / 840 100 log2 3 0.386284722222\n",
      "447 / 840 100 log2 3 0.410590277778\n",
      "448 / 840 100 log2 3 0.415798611111\n",
      "449 / 840 100 log2 3 0.384548611111\n",
      "450 / 840 100 log2 3 0.386284722222\n",
      "451 / 840 100 log2 5 0.435763888889\n",
      "452 / 840 100 log2 5 0.430555555556\n",
      "453 / 840 100 log2 5 0.4453125\n",
      "454 / 840 100 log2 5 0.4375\n",
      "455 / 840 100 log2 5 0.434895833333\n",
      "456 / 840 100 log2 10 0.5703125\n",
      "457 / 840 100 log2 10 0.5703125\n",
      "458 / 840 100 log2 10 0.559895833333\n",
      "459 / 840 100 log2 10 0.573784722222\n",
      "460 / 840 100 log2 10 0.5625\n",
      "461 / 840 100 log2 20 0.620659722222\n",
      "462 / 840 100 log2 20 0.615451388889\n",
      "463 / 840 100 log2 20 0.621527777778\n",
      "464 / 840 100 log2 20 0.618923611111\n",
      "465 / 840 100 log2 20 0.624131944444\n",
      "466 / 840 100 log2 50 0.618923611111\n",
      "467 / 840 100 log2 50 0.618055555556\n",
      "468 / 840 100 log2 50 0.612847222222\n",
      "469 / 840 100 log2 50 0.621527777778\n",
      "470 / 840 100 log2 50 0.609375\n",
      "471 / 840 100 log2 70 0.615451388889\n",
      "472 / 840 100 log2 70 0.622395833333\n",
      "473 / 840 100 log2 70 0.620659722222\n",
      "474 / 840 100 log2 70 0.612847222222\n",
      "475 / 840 100 log2 70 0.624131944444\n",
      "476 / 840 100 log2 100 0.6171875\n",
      "477 / 840 100 log2 100 0.624131944444\n",
      "478 / 840 100 log2 100 0.618055555556\n",
      "479 / 840 100 log2 100 0.618055555556\n",
      "480 / 840 100 log2 100 0.615451388889\n",
      "481 / 840 200 auto 1 0.266493055556\n",
      "482 / 840 200 auto 1 0.306423611111\n",
      "483 / 840 200 auto 1 0.313368055556\n",
      "484 / 840 200 auto 1 0.292534722222\n",
      "485 / 840 200 auto 1 0.297743055556\n",
      "486 / 840 200 auto 3 0.381076388889\n",
      "487 / 840 200 auto 3 0.379340277778\n",
      "488 / 840 200 auto 3 0.368055555556\n",
      "489 / 840 200 auto 3 0.368923611111\n",
      "490 / 840 200 auto 3 0.389756944444\n",
      "491 / 840 200 auto 5 0.434027777778\n",
      "492 / 840 200 auto 5 0.435763888889\n",
      "493 / 840 200 auto 5 0.435763888889\n",
      "494 / 840 200 auto 5 0.434027777778\n",
      "495 / 840 200 auto 5 0.432291666667\n",
      "496 / 840 200 auto 10 0.559027777778\n",
      "497 / 840 200 auto 10 0.572916666667\n",
      "498 / 840 200 auto 10 0.572048611111\n",
      "499 / 840 200 auto 10 0.578125\n",
      "500 / 840 200 auto 10 0.569444444444\n",
      "501 / 840 200 auto 20 0.625868055556\n",
      "502 / 840 200 auto 20 0.621527777778\n",
      "503 / 840 200 auto 20 0.631076388889\n",
      "504 / 840 200 auto 20 0.622395833333\n",
      "505 / 840 200 auto 20 0.6171875\n",
      "506 / 840 200 auto 50 0.622395833333\n",
      "507 / 840 200 auto 50 0.631076388889\n",
      "508 / 840 200 auto 50 0.618055555556\n",
      "509 / 840 200 auto 50 0.638020833333\n",
      "510 / 840 200 auto 50 0.621527777778\n",
      "511 / 840 200 auto 70 0.626736111111\n",
      "512 / 840 200 auto 70 0.630208333333\n",
      "513 / 840 200 auto 70 0.628472222222\n",
      "514 / 840 200 auto 70 0.627604166667\n",
      "515 / 840 200 auto 70 0.631076388889\n",
      "516 / 840 200 auto 100 0.629340277778\n",
      "517 / 840 200 auto 100 0.623263888889\n",
      "518 / 840 200 auto 100 0.618923611111\n",
      "519 / 840 200 auto 100 0.635416666667\n",
      "520 / 840 200 auto 100 0.626736111111\n",
      "521 / 840 200 sqrt 1 0.293402777778\n",
      "522 / 840 200 sqrt 1 0.279513888889\n",
      "523 / 840 200 sqrt 1 0.288194444444\n",
      "524 / 840 200 sqrt 1 0.314236111111\n",
      "525 / 840 200 sqrt 1 0.296006944444\n",
      "526 / 840 200 sqrt 3 0.361979166667\n",
      "527 / 840 200 sqrt 3 0.363715277778\n",
      "528 / 840 200 sqrt 3 0.369791666667\n",
      "529 / 840 200 sqrt 3 0.354166666667\n",
      "530 / 840 200 sqrt 3 0.368055555556\n",
      "531 / 840 200 sqrt 5 0.4296875\n",
      "532 / 840 200 sqrt 5 0.436631944444\n",
      "533 / 840 200 sqrt 5 0.4296875\n",
      "534 / 840 200 sqrt 5 0.428819444444\n",
      "535 / 840 200 sqrt 5 0.432291666667\n",
      "536 / 840 200 sqrt 10 0.556423611111\n",
      "537 / 840 200 sqrt 10 0.557291666667\n",
      "538 / 840 200 sqrt 10 0.567708333333\n",
      "539 / 840 200 sqrt 10 0.559895833333\n",
      "540 / 840 200 sqrt 10 0.563368055556\n",
      "541 / 840 200 sqrt 20 0.621527777778\n",
      "542 / 840 200 sqrt 20 0.628472222222\n",
      "543 / 840 200 sqrt 20 0.628472222222\n",
      "544 / 840 200 sqrt 20 0.622395833333\n",
      "545 / 840 200 sqrt 20 0.631944444444\n",
      "546 / 840 200 sqrt 50 0.625868055556\n",
      "547 / 840 200 sqrt 50 0.624131944444\n",
      "548 / 840 200 sqrt 50 0.625868055556\n",
      "549 / 840 200 sqrt 50 0.618055555556\n",
      "550 / 840 200 sqrt 50 0.616319444444\n",
      "551 / 840 200 sqrt 70 0.620659722222\n",
      "552 / 840 200 sqrt 70 0.618923611111\n",
      "553 / 840 200 sqrt 70 0.626736111111\n",
      "554 / 840 200 sqrt 70 0.630208333333\n",
      "555 / 840 200 sqrt 70 0.627604166667\n",
      "556 / 840 200 sqrt 100 0.628472222222\n",
      "557 / 840 200 sqrt 100 0.6171875\n",
      "558 / 840 200 sqrt 100 0.622395833333\n",
      "559 / 840 200 sqrt 100 0.620659722222\n",
      "560 / 840 200 sqrt 100 0.631076388889\n",
      "561 / 840 200 log2 1 0.297743055556\n",
      "562 / 840 200 log2 1 0.299479166667\n",
      "563 / 840 200 log2 1 0.299479166667\n",
      "564 / 840 200 log2 1 0.299479166667\n",
      "565 / 840 200 log2 1 0.299479166667\n",
      "566 / 840 200 log2 3 0.376736111111\n",
      "567 / 840 200 log2 3 0.393229166667\n",
      "568 / 840 200 log2 3 0.370659722222\n",
      "569 / 840 200 log2 3 0.405381944444\n",
      "570 / 840 200 log2 3 0.388888888889\n",
      "571 / 840 200 log2 5 0.433159722222\n",
      "572 / 840 200 log2 5 0.442708333333\n",
      "573 / 840 200 log2 5 0.431423611111\n",
      "574 / 840 200 log2 5 0.439236111111\n",
      "575 / 840 200 log2 5 0.428819444444\n",
      "576 / 840 200 log2 10 0.566840277778\n",
      "577 / 840 200 log2 10 0.572916666667\n",
      "578 / 840 200 log2 10 0.571180555556\n",
      "579 / 840 200 log2 10 0.564236111111\n",
      "580 / 840 200 log2 10 0.572916666667\n",
      "581 / 840 200 log2 20 0.616319444444\n",
      "582 / 840 200 log2 20 0.616319444444\n",
      "583 / 840 200 log2 20 0.621527777778\n",
      "584 / 840 200 log2 20 0.6171875\n",
      "585 / 840 200 log2 20 0.619791666667\n",
      "586 / 840 200 log2 50 0.624131944444\n",
      "587 / 840 200 log2 50 0.6171875\n",
      "588 / 840 200 log2 50 0.624131944444\n",
      "589 / 840 200 log2 50 0.620659722222\n",
      "590 / 840 200 log2 50 0.616319444444\n",
      "591 / 840 200 log2 70 0.605902777778\n",
      "592 / 840 200 log2 70 0.635416666667\n",
      "593 / 840 200 log2 70 0.624131944444\n",
      "594 / 840 200 log2 70 0.627604166667\n",
      "595 / 840 200 log2 70 0.611979166667\n",
      "596 / 840 200 log2 100 0.611111111111\n",
      "597 / 840 200 log2 100 0.620659722222\n",
      "598 / 840 200 log2 100 0.626736111111\n",
      "599 / 840 200 log2 100 0.626736111111\n",
      "600 / 840 200 log2 100 0.625\n",
      "601 / 840 300 auto 1 0.277777777778\n",
      "602 / 840 300 auto 1 0.334201388889\n",
      "603 / 840 300 auto 1 0.290798611111\n",
      "604 / 840 300 auto 1 0.302951388889\n",
      "605 / 840 300 auto 1 0.310763888889\n",
      "606 / 840 300 auto 3 0.384548611111\n",
      "607 / 840 300 auto 3 0.375\n",
      "608 / 840 300 auto 3 0.372395833333\n",
      "609 / 840 300 auto 3 0.362847222222\n",
      "610 / 840 300 auto 3 0.370659722222\n",
      "611 / 840 300 auto 5 0.433159722222\n",
      "612 / 840 300 auto 5 0.426215277778\n",
      "613 / 840 300 auto 5 0.431423611111\n",
      "614 / 840 300 auto 5 0.433159722222\n",
      "615 / 840 300 auto 5 0.4296875\n",
      "616 / 840 300 auto 10 0.559027777778\n",
      "617 / 840 300 auto 10 0.558159722222\n",
      "618 / 840 300 auto 10 0.574652777778\n",
      "619 / 840 300 auto 10 0.569444444444\n",
      "620 / 840 300 auto 10 0.5625\n",
      "621 / 840 300 auto 20 0.623263888889\n",
      "622 / 840 300 auto 20 0.620659722222\n",
      "623 / 840 300 auto 20 0.625868055556\n",
      "624 / 840 300 auto 20 0.630208333333\n",
      "625 / 840 300 auto 20 0.620659722222\n",
      "626 / 840 300 auto 50 0.625\n",
      "627 / 840 300 auto 50 0.635416666667\n",
      "628 / 840 300 auto 50 0.625\n",
      "629 / 840 300 auto 50 0.621527777778\n",
      "630 / 840 300 auto 50 0.619791666667\n",
      "631 / 840 300 auto 70 0.625\n",
      "632 / 840 300 auto 70 0.625868055556\n",
      "633 / 840 300 auto 70 0.629340277778\n",
      "634 / 840 300 auto 70 0.627604166667\n",
      "635 / 840 300 auto 70 0.626736111111\n",
      "636 / 840 300 auto 100 0.625\n",
      "637 / 840 300 auto 100 0.631076388889\n",
      "638 / 840 300 auto 100 0.625\n",
      "639 / 840 300 auto 100 0.6171875\n",
      "640 / 840 300 auto 100 0.6171875\n",
      "641 / 840 300 sqrt 1 0.305555555556\n",
      "642 / 840 300 sqrt 1 0.278645833333\n",
      "643 / 840 300 sqrt 1 0.307291666667\n",
      "644 / 840 300 sqrt 1 0.290798611111\n",
      "645 / 840 300 sqrt 1 0.297743055556\n",
      "646 / 840 300 sqrt 3 0.368923611111\n",
      "647 / 840 300 sqrt 3 0.3828125\n",
      "648 / 840 300 sqrt 3 0.355034722222\n",
      "649 / 840 300 sqrt 3 0.368923611111\n",
      "650 / 840 300 sqrt 3 0.380208333333\n",
      "651 / 840 300 sqrt 5 0.433159722222\n",
      "652 / 840 300 sqrt 5 0.427951388889\n",
      "653 / 840 300 sqrt 5 0.440104166667\n",
      "654 / 840 300 sqrt 5 0.4375\n",
      "655 / 840 300 sqrt 5 0.427083333333\n",
      "656 / 840 300 sqrt 10 0.576388888889\n",
      "657 / 840 300 sqrt 10 0.559027777778\n",
      "658 / 840 300 sqrt 10 0.566840277778\n",
      "659 / 840 300 sqrt 10 0.564236111111\n",
      "660 / 840 300 sqrt 10 0.564236111111\n",
      "661 / 840 300 sqrt 20 0.625868055556\n",
      "662 / 840 300 sqrt 20 0.6328125\n",
      "663 / 840 300 sqrt 20 0.636284722222\n",
      "664 / 840 300 sqrt 20 0.629340277778\n",
      "665 / 840 300 sqrt 20 0.631944444444\n",
      "666 / 840 300 sqrt 50 0.635416666667\n",
      "667 / 840 300 sqrt 50 0.634548611111\n",
      "668 / 840 300 sqrt 50 0.631944444444\n",
      "669 / 840 300 sqrt 50 0.619791666667\n",
      "670 / 840 300 sqrt 50 0.630208333333\n",
      "671 / 840 300 sqrt 70 0.628472222222\n",
      "672 / 840 300 sqrt 70 0.625868055556\n",
      "673 / 840 300 sqrt 70 0.625868055556\n",
      "674 / 840 300 sqrt 70 0.624131944444\n",
      "675 / 840 300 sqrt 70 0.626736111111\n",
      "676 / 840 300 sqrt 100 0.629340277778\n",
      "677 / 840 300 sqrt 100 0.629340277778\n",
      "678 / 840 300 sqrt 100 0.628472222222\n",
      "679 / 840 300 sqrt 100 0.625868055556\n",
      "680 / 840 300 sqrt 100 0.631076388889\n",
      "681 / 840 300 log2 1 0.297743055556\n",
      "682 / 840 300 log2 1 0.299479166667\n",
      "683 / 840 300 log2 1 0.294270833333\n",
      "684 / 840 300 log2 1 0.294270833333\n",
      "685 / 840 300 log2 1 0.296006944444\n",
      "686 / 840 300 log2 3 0.401909722222\n",
      "687 / 840 300 log2 3 0.401909722222\n",
      "688 / 840 300 log2 3 0.393229166667\n",
      "689 / 840 300 log2 3 0.378472222222\n",
      "690 / 840 300 log2 3 0.396701388889\n",
      "691 / 840 300 log2 5 0.436631944444\n",
      "692 / 840 300 log2 5 0.440104166667\n",
      "693 / 840 300 log2 5 0.4296875\n",
      "694 / 840 300 log2 5 0.434895833333\n",
      "695 / 840 300 log2 5 0.441840277778\n",
      "696 / 840 300 log2 10 0.571180555556\n",
      "697 / 840 300 log2 10 0.563368055556\n",
      "698 / 840 300 log2 10 0.574652777778\n",
      "699 / 840 300 log2 10 0.563368055556\n",
      "700 / 840 300 log2 10 0.575520833333\n",
      "701 / 840 300 log2 20 0.620659722222\n",
      "702 / 840 300 log2 20 0.623263888889\n",
      "703 / 840 300 log2 20 0.625868055556\n",
      "704 / 840 300 log2 20 0.628472222222\n",
      "705 / 840 300 log2 20 0.619791666667\n",
      "706 / 840 300 log2 50 0.628472222222\n",
      "707 / 840 300 log2 50 0.621527777778\n",
      "708 / 840 300 log2 50 0.628472222222\n",
      "709 / 840 300 log2 50 0.6171875\n",
      "710 / 840 300 log2 50 0.615451388889\n",
      "711 / 840 300 log2 70 0.630208333333\n",
      "712 / 840 300 log2 70 0.623263888889\n",
      "713 / 840 300 log2 70 0.624131944444\n",
      "714 / 840 300 log2 70 0.625868055556\n",
      "715 / 840 300 log2 70 0.618055555556\n",
      "716 / 840 300 log2 100 0.623263888889\n",
      "717 / 840 300 log2 100 0.619791666667\n",
      "718 / 840 300 log2 100 0.624131944444\n",
      "719 / 840 300 log2 100 0.620659722222\n",
      "720 / 840 300 log2 100 0.625\n",
      "721 / 840 500 auto 1 0.292534722222\n",
      "722 / 840 500 auto 1 0.3203125\n",
      "723 / 840 500 auto 1 0.317708333333\n",
      "724 / 840 500 auto 1 0.296006944444\n",
      "725 / 840 500 auto 1 0.287326388889\n",
      "726 / 840 500 auto 3 0.378472222222\n",
      "727 / 840 500 auto 3 0.374131944444\n",
      "728 / 840 500 auto 3 0.374131944444\n",
      "729 / 840 500 auto 3 0.371527777778\n",
      "730 / 840 500 auto 3 0.377604166667\n",
      "731 / 840 500 auto 5 0.428819444444\n",
      "732 / 840 500 auto 5 0.432291666667\n",
      "733 / 840 500 auto 5 0.434027777778\n",
      "734 / 840 500 auto 5 0.425347222222\n",
      "735 / 840 500 auto 5 0.436631944444\n",
      "736 / 840 500 auto 10 0.5703125\n",
      "737 / 840 500 auto 10 0.568576388889\n",
      "738 / 840 500 auto 10 0.565972222222\n",
      "739 / 840 500 auto 10 0.573784722222\n",
      "740 / 840 500 auto 10 0.572916666667\n",
      "741 / 840 500 auto 20 0.625868055556\n",
      "742 / 840 500 auto 20 0.634548611111\n",
      "743 / 840 500 auto 20 0.633680555556\n",
      "744 / 840 500 auto 20 0.625868055556\n",
      "745 / 840 500 auto 20 0.626736111111\n",
      "746 / 840 500 auto 50 0.628472222222\n",
      "747 / 840 500 auto 50 0.631076388889\n",
      "748 / 840 500 auto 50 0.631944444444\n",
      "749 / 840 500 auto 50 0.631944444444\n",
      "750 / 840 500 auto 50 0.623263888889\n",
      "751 / 840 500 auto 70 0.631076388889\n",
      "752 / 840 500 auto 70 0.6328125\n",
      "753 / 840 500 auto 70 0.625\n",
      "754 / 840 500 auto 70 0.621527777778\n",
      "755 / 840 500 auto 70 0.633680555556\n",
      "756 / 840 500 auto 100 0.618923611111\n",
      "757 / 840 500 auto 100 0.628472222222\n",
      "758 / 840 500 auto 100 0.625868055556\n",
      "759 / 840 500 auto 100 0.629340277778\n",
      "760 / 840 500 auto 100 0.631076388889\n",
      "761 / 840 500 sqrt 1 0.322048611111\n",
      "762 / 840 500 sqrt 1 0.3125\n",
      "763 / 840 500 sqrt 1 0.279513888889\n",
      "764 / 840 500 sqrt 1 0.321180555556\n",
      "765 / 840 500 sqrt 1 0.303819444444\n",
      "766 / 840 500 sqrt 3 0.379340277778\n",
      "767 / 840 500 sqrt 3 0.368923611111\n",
      "768 / 840 500 sqrt 3 0.378472222222\n",
      "769 / 840 500 sqrt 3 0.366319444444\n",
      "770 / 840 500 sqrt 3 0.371527777778\n",
      "771 / 840 500 sqrt 5 0.430555555556\n",
      "772 / 840 500 sqrt 5 0.436631944444\n",
      "773 / 840 500 sqrt 5 0.4375\n",
      "774 / 840 500 sqrt 5 0.436631944444\n",
      "775 / 840 500 sqrt 5 0.436631944444\n",
      "776 / 840 500 sqrt 10 0.569444444444\n",
      "777 / 840 500 sqrt 10 0.568576388889\n",
      "778 / 840 500 sqrt 10 0.573784722222\n",
      "779 / 840 500 sqrt 10 0.565104166667\n",
      "780 / 840 500 sqrt 10 0.5625\n",
      "781 / 840 500 sqrt 20 0.621527777778\n",
      "782 / 840 500 sqrt 20 0.625868055556\n",
      "783 / 840 500 sqrt 20 0.625\n",
      "784 / 840 500 sqrt 20 0.630208333333\n",
      "785 / 840 500 sqrt 20 0.6171875\n",
      "786 / 840 500 sqrt 50 0.620659722222\n",
      "787 / 840 500 sqrt 50 0.631076388889\n",
      "788 / 840 500 sqrt 50 0.630208333333\n",
      "789 / 840 500 sqrt 50 0.619791666667\n",
      "790 / 840 500 sqrt 50 0.620659722222\n",
      "791 / 840 500 sqrt 70 0.626736111111\n",
      "792 / 840 500 sqrt 70 0.628472222222\n",
      "793 / 840 500 sqrt 70 0.629340277778\n",
      "794 / 840 500 sqrt 70 0.631944444444\n",
      "795 / 840 500 sqrt 70 0.629340277778\n",
      "796 / 840 500 sqrt 100 0.635416666667\n",
      "797 / 840 500 sqrt 100 0.628472222222\n",
      "798 / 840 500 sqrt 100 0.631944444444\n",
      "799 / 840 500 sqrt 100 0.621527777778\n",
      "800 / 840 500 sqrt 100 0.627604166667\n",
      "801 / 840 500 log2 1 0.299479166667\n",
      "802 / 840 500 log2 1 0.299479166667\n",
      "803 / 840 500 log2 1 0.299479166667\n",
      "804 / 840 500 log2 1 0.299479166667\n",
      "805 / 840 500 log2 1 0.299479166667\n",
      "806 / 840 500 log2 3 0.378472222222\n",
      "807 / 840 500 log2 3 0.391493055556\n",
      "808 / 840 500 log2 3 0.396701388889\n",
      "809 / 840 500 log2 3 0.395833333333\n",
      "810 / 840 500 log2 3 0.384548611111\n",
      "811 / 840 500 log2 5 0.434027777778\n",
      "812 / 840 500 log2 5 0.433159722222\n",
      "813 / 840 500 log2 5 0.4375\n",
      "814 / 840 500 log2 5 0.427083333333\n",
      "815 / 840 500 log2 5 0.430555555556\n",
      "816 / 840 500 log2 10 0.575520833333\n",
      "817 / 840 500 log2 10 0.572916666667\n",
      "818 / 840 500 log2 10 0.574652777778\n",
      "819 / 840 500 log2 10 0.567708333333\n",
      "820 / 840 500 log2 10 0.574652777778\n",
      "821 / 840 500 log2 20 0.625868055556\n",
      "822 / 840 500 log2 20 0.628472222222\n",
      "823 / 840 500 log2 20 0.630208333333\n",
      "824 / 840 500 log2 20 0.6171875\n",
      "825 / 840 500 log2 20 0.623263888889\n",
      "826 / 840 500 log2 50 0.621527777778\n",
      "827 / 840 500 log2 50 0.622395833333\n",
      "828 / 840 500 log2 50 0.626736111111\n",
      "829 / 840 500 log2 50 0.625868055556\n",
      "830 / 840 500 log2 50 0.621527777778\n",
      "831 / 840 500 log2 70 0.626736111111\n",
      "832 / 840 500 log2 70 0.628472222222\n",
      "833 / 840 500 log2 70 0.625868055556\n",
      "834 / 840 500 log2 70 0.625868055556\n",
      "835 / 840 500 log2 70 0.620659722222\n",
      "836 / 840 500 log2 100 0.631944444444\n",
      "837 / 840 500 log2 100 0.628472222222\n",
      "838 / 840 500 log2 100 0.625\n",
      "839 / 840 500 log2 100 0.625868055556\n",
      "840 / 840 500 log2 100 0.618923611111\n"
     ]
    }
   ],
   "source": [
    "n_estimators=[10,30,50,100,200,300,500]\n",
    "max_features=['auto', 'sqrt', 'log2']\n",
    "max_depth=[1,3,5,10,20,50,70,100]\n",
    "cv_n=5\n",
    "res=pd.DataFrame(columns=['n_estimators','max_features','max_depth','score'])\n",
    "k=0\n",
    "maxk=len(n_estimators)*len(max_features)*len(max_depth)*cv_n\n",
    "for n_ in n_estimators:\n",
    "    for mf_ in max_features:\n",
    "        for md_ in max_depth:\n",
    "            for i in range(cv_n):\n",
    "                k=k+1\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_train, all_target, test_size=0.33, random_state=42)\n",
    "                X_res, y_res = ros.fit_sample(X_train,y_train)\n",
    "                X_res=pd.DataFrame(X_res,columns=base_col)\n",
    "                clf=RandomForestClassifier(max_features=mf_,n_estimators=n_,max_depth=md_)\n",
    "                clf.fit(X_res[best_cols],y_res)\n",
    "                score=clf.score(X_test[best_cols],y_test)\n",
    "                row=pd.Series(data=[n_,mf_,md_,score],index=['n_estimators','max_features','max_depth','score'])\n",
    "                res.loc[len(res)]=row\n",
    "                print (k,\"/\",maxk,n_,mf_,md_,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.631250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.630382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>500.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.629340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>500.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.629340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>500.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.629167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>500.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.628993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>500.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.628819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>200.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.628819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.628819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>300.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.626910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>500.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.626736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>200.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.626736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>200.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.626563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.626215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.626215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>200.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.626215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>500.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.626042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>500.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.625521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>300.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.625347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>500.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>200.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.624826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>500.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.624479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>300.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.624306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>300.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.624132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>500.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.623958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>200.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.623958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>200.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.623611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>100.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.623611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>300.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.623611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>500.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.623611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>300.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.373090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>500.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.372917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.371701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.371181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>30.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.370312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>50.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.363715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>200.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.363542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.362674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.352431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.325521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>100.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.315451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.312674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.312326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>500.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.307812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>50.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.307812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>50.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.305903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>30.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.305382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>300.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.303299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>500.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.302778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>30.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.301042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>100.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.300694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>500.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.299479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>200.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.299132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.299132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>100.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.299132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>50.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.298264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>300.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.296354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>300.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.296007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>200.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.295313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>200.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.294271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_estimators max_features  max_depth     score\n",
       "140         300.0         sqrt       20.0  0.631250\n",
       "141         300.0         sqrt       50.0  0.630382\n",
       "148         500.0         auto       20.0  0.629340\n",
       "149         500.0         auto       50.0  0.629340\n",
       "166         500.0         sqrt       70.0  0.629167\n",
       "167         500.0         sqrt      100.0  0.628993\n",
       "150         500.0         auto       70.0  0.628819\n",
       "102         200.0         auto       70.0  0.628819\n",
       "143         300.0         sqrt      100.0  0.628819\n",
       "126         300.0         auto       70.0  0.626910\n",
       "151         500.0         auto      100.0  0.626736\n",
       "103         200.0         auto      100.0  0.626736\n",
       "116         200.0         sqrt       20.0  0.626563\n",
       "93          100.0         sqrt       50.0  0.626215\n",
       "142         300.0         sqrt       70.0  0.626215\n",
       "101         200.0         auto       50.0  0.626215\n",
       "159         500.0         log2      100.0  0.626042\n",
       "158         500.0         log2       70.0  0.625521\n",
       "125         300.0         auto       50.0  0.625347\n",
       "156         500.0         log2       20.0  0.625000\n",
       "118         200.0         sqrt       70.0  0.624826\n",
       "165         500.0         sqrt       50.0  0.624479\n",
       "134         300.0         log2       70.0  0.624306\n",
       "124         300.0         auto       20.0  0.624132\n",
       "164         500.0         sqrt       20.0  0.623958\n",
       "119         200.0         sqrt      100.0  0.623958\n",
       "100         200.0         auto       20.0  0.623611\n",
       "77          100.0         auto       50.0  0.623611\n",
       "132         300.0         log2       20.0  0.623611\n",
       "157         500.0         log2       50.0  0.623611\n",
       "..            ...          ...        ...       ...\n",
       "121         300.0         auto        3.0  0.373090\n",
       "161         500.0         sqrt        3.0  0.372917\n",
       "89          100.0         sqrt        3.0  0.371701\n",
       "137         300.0         sqrt        3.0  0.371181\n",
       "41           30.0         sqrt        3.0  0.370312\n",
       "65           50.0         sqrt        3.0  0.363715\n",
       "113         200.0         sqrt        3.0  0.363542\n",
       "17           10.0         sqrt        3.0  0.362674\n",
       "1            10.0         auto        3.0  0.352431\n",
       "0            10.0         auto        1.0  0.325521\n",
       "88          100.0         sqrt        1.0  0.315451\n",
       "8            10.0         log2        1.0  0.312674\n",
       "16           10.0         sqrt        1.0  0.312326\n",
       "160         500.0         sqrt        1.0  0.307812\n",
       "64           50.0         sqrt        1.0  0.307812\n",
       "48           50.0         auto        1.0  0.305903\n",
       "32           30.0         log2        1.0  0.305382\n",
       "120         300.0         auto        1.0  0.303299\n",
       "144         500.0         auto        1.0  0.302778\n",
       "40           30.0         sqrt        1.0  0.301042\n",
       "72          100.0         auto        1.0  0.300694\n",
       "152         500.0         log2        1.0  0.299479\n",
       "104         200.0         log2        1.0  0.299132\n",
       "24           30.0         auto        1.0  0.299132\n",
       "80          100.0         log2        1.0  0.299132\n",
       "56           50.0         log2        1.0  0.298264\n",
       "128         300.0         log2        1.0  0.296354\n",
       "136         300.0         sqrt        1.0  0.296007\n",
       "96          200.0         auto        1.0  0.295313\n",
       "112         200.0         sqrt        1.0  0.294271\n",
       "\n",
       "[168 rows x 4 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=res.groupby(as_index=False,by=['n_estimators','max_features','max_depth'])['score'].mean()\n",
    "p.sort_values(by='score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.630569809507\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(max_features='auto',n_estimators=300,max_depth=100,random_state=42)\n",
    "print (np.mean(cross_val_score(rf, all_train[best_cols], all_target, cv=5)))\n",
    "# 0.634280777033   ,class_weight=\"balanced\"\n",
    "# 0.630569809507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_file=open('result.csv', 'w')\n",
    "for y_item in Y_pred:\n",
    "    res_file.write(\"%s\\n\" % y_item)\n",
    "res_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\scikitplot\\classifiers.py:51: UserWarning: \"plot_precision_recall_curve\" method already in clf. Overriding anyway. This may result in unintended behavior.\n",
      "  'Overriding anyway. This may result in unintended behavior.'.format(key))\n",
      "D:\\Anaconda3\\lib\\site-packages\\scikitplot\\classifiers.py:51: UserWarning: \"plot_confusion_matrix\" method already in clf. Overriding anyway. This may result in unintended behavior.\n",
      "  'Overriding anyway. This may result in unintended behavior.'.format(key))\n",
      "D:\\Anaconda3\\lib\\site-packages\\scikitplot\\classifiers.py:51: UserWarning: \"plot_ks_statistic\" method already in clf. Overriding anyway. This may result in unintended behavior.\n",
      "  'Overriding anyway. This may result in unintended behavior.'.format(key))\n",
      "D:\\Anaconda3\\lib\\site-packages\\scikitplot\\classifiers.py:51: UserWarning: \"plot_learning_curve\" method already in clf. Overriding anyway. This may result in unintended behavior.\n",
      "  'Overriding anyway. This may result in unintended behavior.'.format(key))\n",
      "D:\\Anaconda3\\lib\\site-packages\\scikitplot\\classifiers.py:51: UserWarning: \"plot_feature_importances\" method already in clf. Overriding anyway. This may result in unintended behavior.\n",
      "  'Overriding anyway. This may result in unintended behavior.'.format(key))\n",
      "D:\\Anaconda3\\lib\\site-packages\\scikitplot\\classifiers.py:51: UserWarning: \"plot_roc_curve\" method already in clf. Overriding anyway. This may result in unintended behavior.\n",
      "  'Overriding anyway. This may result in unintended behavior.'.format(key))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFMCAYAAAAA3S/0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d9678284e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAFbCAYAAADFtbf1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d967879780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf1= classifier_factory(rf)\n",
    "cf1.fit(X[best_cols], y)\n",
    "cf1.plot_feature_importances(feature_names=best_cols)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz0AAAMyCAYAAABHPq+gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIC89v8BGkAHo3Sfh74AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d967f24748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(random_state=1)\n",
    "pca.fit(X)\n",
    "skplt.plot_pca_component_variance(pca)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
